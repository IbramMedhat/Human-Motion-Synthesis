{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6oWUCJCnPmT",
    "outputId": "ff69467f-8448-4bca-9677-0f6de49a4388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import Model as Model_\n",
    "from tensorflow.keras.layers import Input, ReLU, LSTM, Dense, TimeDistributed, Bidirectional, Normalization, GaussianNoise \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_model_remediation.min_diff.losses.mmd_loss as MMD\n",
    "import tensorflow_model_remediation.min_diff.losses.adjusted_mmd_loss as adjustedMMD\n",
    "\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1wLcoRN_q6H",
    "outputId": "2539f137-5031-49c5-97e6-58097f137e1c"
   },
   "outputs": [],
   "source": [
    "#Need only to be used with google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVYkmolC_bDI",
    "outputId": "343f646f-7dab-4c4d-eb9f-6b4f3f26e0d7"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow_model_remediation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ikRIhsrrnhlH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "class Dataset_Preprocessing:\n",
    "    def __init__(self, dir_path, include_dimension = 2, sample_size = 50, total_classes = 17, datatype = 'float32'):\n",
    "        \n",
    "        #Dataset Directory path\n",
    "        self.dir_path = dir_path\n",
    "        \n",
    "        #Which Dimension file to include, possible values: 2 and 3\n",
    "        self.include_dimension = include_dimension\n",
    "        \n",
    "        #Total frames in one Sample\n",
    "        self.sample_size = sample_size\n",
    "        \n",
    "        #Default Datatype for all the samples\n",
    "        self.datatype = datatype\n",
    "        \n",
    "        #Activity classes to include\n",
    "        self.classes = ['SittingDown', 'Walking', 'Directions', 'Discussion', 'Sitting', 'Phoning', 'Eating', 'Posing', 'Greeting', 'Smoking']\n",
    "        \n",
    "        #Total activity classes\n",
    "        self.total_classes = len(self.classes)\n",
    "        \n",
    "        #Subject Folders names in the Dataset\n",
    "        self.internal_folders = ['S1', 'S5','S6','S7','S8','S9','S11']\n",
    "    \n",
    "    def read_dataset(self):\n",
    "        try:\n",
    "            #Contains all the different activity vectors\n",
    "            activity_vector = {}\n",
    "            \n",
    "            #Contains the overall dataset\n",
    "            sampled_data = None\n",
    "            \n",
    "            #Based on dimensions, which folder to use for extracting the dataset files\n",
    "            data_folder = 'Poses_D2_Positions' if self.include_dimension == 2 else 'Poses_D3_Positions'\n",
    "            \n",
    "            #Checking if the dataset path is valid\n",
    "            if not os.path.exists(self.dir_path):\n",
    "                print('The Data Directory Does not Exist!')\n",
    "                return None\n",
    "\n",
    "            #Iterating over all the subject folders\n",
    "            for fld in self.internal_folders:\n",
    "                #Iterating for each file in the specified folder\n",
    "                for file in os.listdir(os.path.join(self.dir_path, fld, data_folder)):\n",
    "                    #Extracting the activity from the filename\n",
    "                    activity = self.__extract_activity(file)\n",
    "                    \n",
    "                    if activity not in self.classes:\n",
    "                        continue\n",
    "                    \n",
    "                    #Reading the CSV file using Pandas\n",
    "                    data = pd.read_csv(os.path.join(self.dir_path, fld, data_folder, file), header=None)\n",
    "\n",
    "                    #Formulating the activity vector using one hot encoding\n",
    "                    if activity not in activity_vector:\n",
    "                        total_keys = len(activity_vector.keys())\n",
    "                        activity_vector[activity] = np.zeros(self.total_classes)\n",
    "                        activity_vector[activity][total_keys] = 1\n",
    "                    vector = activity_vector[activity]\n",
    "                    \n",
    "                    #Sampling the dataset\n",
    "                    grouped_sample = self.__group_samples(data, self.sample_size, vector)\n",
    "                    sampled_data = grouped_sample if sampled_data is None else np.append(sampled_data, grouped_sample, axis=0)\n",
    "            \n",
    "            #Changing the Datatype\n",
    "            sampled_data = sampled_data.astype(self.datatype)\n",
    "            \n",
    "            return sampled_data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def __extract_activity(self, filename):\n",
    "        try:\n",
    "            #Extracting the filename and excluding the extension\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            \n",
    "            #Substituting the empty string with characters other than english alphabets\n",
    "            activity = re.sub('[^A-Za-z]+' , '' , name)\n",
    "            return activity\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def __group_samples(self, dataset, sample_size, activity):\n",
    "        try:\n",
    "            #Checking if the dataset is a Pandas Dataframe\n",
    "            if not isinstance(dataset, pd.DataFrame):\n",
    "                print('Expecting Pandas Dataframe, but got {}'.format(type(dataset)))\n",
    "                return None\n",
    "            \n",
    "            #Appending activity class to each row in the dataset\n",
    "            dataset = pd.concat([dataset, pd.DataFrame(np.tile(activity, (dataset.shape[0],1)))], axis=1)\n",
    "            \n",
    "            #Reshaping the dataset into sample batches\n",
    "            total_samples = dataset.shape[0]//sample_size\n",
    "            total_features = dataset.shape[1]\n",
    "            grouped_rows = dataset.to_numpy()[:total_samples*self.sample_size].reshape((-1,self.sample_size, total_features))\n",
    "            \n",
    "            return grouped_rows\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f8PgK1UVnkrw"
   },
   "outputs": [],
   "source": [
    "#For long term prediction, we need a sample size of 60(10 frames input sequance, 50 frames predicted sequance)\n",
    "sampled_data = Dataset_Preprocessing('./H3.6csv', sample_size=60).read_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ4Vt5JFJYLY"
   },
   "source": [
    "## Splitting dataset to features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8nABIG0rnxl_"
   },
   "outputs": [],
   "source": [
    "def split_to_features_labels(dataset, input_sequance_size=10) :\n",
    "    \"\"\"\n",
    "    Function for splitting the data into features(with sequance size=iput_sequance_size)\n",
    "    and labels which should be the remainder of the sample length \n",
    "    \"\"\"\n",
    "    assert input_sequance_size < dataset.shape[1], f\"input sequance should be smaller than the total sample size\"\n",
    "    features = dataset[:, np.s_[0:input_sequance_size], :]\n",
    "    labels = dataset[:,np.s_[input_sequance_size:], :64]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lw6Tvviol_Ch"
   },
   "outputs": [],
   "source": [
    "#To make the data divisible for batch size of 20\n",
    "total_batches = sampled_data.shape[0]\n",
    "sampled_data = sampled_data[:total_batches-(total_batches%20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h6bSQTwdn2Fo"
   },
   "outputs": [],
   "source": [
    "sampled_dataX, sampled_dataY = split_to_features_labels(sampled_data, input_sequance_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVXQiscVn4O2",
    "outputId": "16b74b2e-2707-4115-943d-dc1b320fc83e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 25520\n",
      "Total Frames: 50\n",
      "Total Features: 64\n"
     ]
    }
   ],
   "source": [
    "print('Total Samples: {}'.format(sampled_dataY.shape[0]))\n",
    "print('Total Frames: {}'.format(sampled_dataY.shape[1]))\n",
    "print('Total Features: {}'.format(sampled_dataY.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snGEPtNOKLvg"
   },
   "source": [
    "## Adding Preprocessing steps to improve model performance and robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(sampled_data, downsample_technique = 'skip'):\n",
    "    \"\"\"\n",
    "    The function used to down-sample the data using two different techniques. In Skip, one frame is skipped consecutively and\n",
    "    in the mean technique, two frames are averaged consecutively.\n",
    "    \"\"\"\n",
    "    samples_per_batch = int(sampled_data.shape[1] / 2)\n",
    "    total_features = sampled_data.shape[2]\n",
    "    downsampled_data = np.empty(shape=(0, samples_per_batch, total_features))\n",
    "    \n",
    "    if downsample_technique == 'skip':\n",
    "        downsampled_data = sampled_data[:,::2,:]\n",
    "    else:\n",
    "        for batch in sampled_data:\n",
    "            averaged_batch = np.empty(shape=(0, total_features))\n",
    "            for i in range(0, batch.shape[0], 2):\n",
    "                averaged_batch = np.append(averaged_batch, np.mean(batch[i:i+2, :], axis = 0).reshape((1, total_features)), axis = 0)\n",
    "            downsampled_data = np.append(downsampled_data, averaged_batch.reshape((1, samples_per_batch, total_features)), axis = 0)\n",
    "    return downsampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VzjeqMm1KNjQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(sampled_dataX, sampled_dataY, normalize=True, add_noise=True, stddev=0.05) :\n",
    "    \"\"\"\n",
    "    Function to preprocess data by normalizing input features and adding guassian\n",
    "    noise to increase model robustness\n",
    "    \"\"\"  \n",
    "    if normalize :\n",
    "        sampled_dataX =  tf.keras.utils.normalize(sampled_dataX, axis=2)\n",
    "    if add_noise :\n",
    "        guassian_noise_layer = tf.keras.layers.GaussianNoise(stddev=stddev)\n",
    "        sampled_dataX = guassian_noise_layer(sampled_dataX)\n",
    "    return sampled_dataX, sampled_dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4bR0E_RfMlHg"
   },
   "outputs": [],
   "source": [
    "preprocessed_sampled_dataX, preprocessed_sampled_dataY = preprocess_data(sampled_dataX, sampled_dataY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_data = downsampling(sampled_data, 'skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_dataX, downsampled_dataY = split_to_features_labels(downsampled_data, input_sequance_size=10)\n",
    "preprocessed_downsampled_dataX, preprocessed_downsampled_dataY = preprocess_data(downsampled_dataX, downsampled_dataY) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwCrXubfJka4"
   },
   "source": [
    "## Defining different components of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QsfCMT-0zRTs"
   },
   "outputs": [],
   "source": [
    "class InterpolationLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom interpolation layer extending the keras layer class\n",
    "    it has one attribute num_frames to be interpolated between each two consecutive \n",
    "    timesteps\n",
    "    it has one main function interpolateFrames  \n",
    "    \"\"\"\n",
    "  \n",
    "    def __init__(self, num_frames=5):\n",
    "        super(InterpolationLayer, self).__init__()\n",
    "        self.num_frames = num_frames\n",
    "       \n",
    "    def interpolateFrames(self, inputs):\n",
    "        \"\"\"\n",
    "        Takes input tensors of shape(batch_size, timesteps, features)\n",
    "        returns interpolated frames with shape(batch_size, timesteps*num_frames, features)\n",
    "        \"\"\"\n",
    "        batch_size = inputs.shape[0]\n",
    "        timesteps = inputs.shape[1]\n",
    "        features = inputs.shape[2]\n",
    "        interpolated_frames = tf.zeros([0, features])\n",
    "\n",
    "        for batch in range(batch_size) :\n",
    "            for t in range(timesteps) :\n",
    "                for j in range(self.num_frames) :\n",
    "                    X_i0 = inputs[batch, t]\n",
    "                    if(t == timesteps-1) :\n",
    "                        X_i1 = inputs[batch, t]\n",
    "                    else :  \n",
    "                        X_i1 = inputs[batch, t+1]\n",
    "                    alpha_j = j/self.num_frames\n",
    "                    current_frame = alpha_j*X_i0 + (1-alpha_j)*X_i1\n",
    "                    current_frame = tf.reshape(current_frame, [1, features])\n",
    "                    interpolated_frames = tf.concat((interpolated_frames, current_frame), axis=0)\n",
    "\n",
    "        interpolated_frames = tf.reshape(interpolated_frames, [batch_size, (timesteps)*self.num_frames, features])\n",
    "        return interpolated_frames\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.interpolateFrames(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7PIJXvLaaEvY"
   },
   "outputs": [],
   "source": [
    "class GlocalNet(Model_):\n",
    "    \"\"\"\n",
    "    A full GlocalNet implementation include the three main stages\n",
    "    Glogen generating initial sparse frames\n",
    "    Interpolation layer generating dense frames from Glogen output\n",
    "    Locgen generating the final output by smoothing the interpolated frames\n",
    "    \"\"\"\n",
    "    def __init__(self, enocder_hidden_state=200, decoder_hidden_state=200, \n",
    "                 output_diminsion=64, LSTM_dropout=0.25, dense_activation='relu',\n",
    "                 interpolation_frames=5, exclude_locgen=False):\n",
    "        super(GlocalNet, self).__init__()\n",
    "        self.exclude_locgen = exclude_locgen\n",
    "        #Glogen layers\n",
    "        self.glogen_encoder = LSTM(enocder_hidden_state, return_state=True\n",
    "                                   , return_sequences=True, dropout=LSTM_dropout)\n",
    "        self.glogen_decoder = LSTM(decoder_hidden_state, return_sequences=True,\n",
    "                                   return_state=True, dropout=LSTM_dropout)\n",
    "        #Locgen layers\n",
    "        self.locgen_encoder = LSTM(enocder_hidden_state, return_sequences=True,\n",
    "                                   return_state=True, dropout=LSTM_dropout)\n",
    "        self.locgen_decoder = LSTM(decoder_hidden_state, return_sequences=True,\n",
    "                                   return_state=True, dropout=LSTM_dropout)\n",
    "        #Glogen dense layer\n",
    "        self.glogen_dense_layer = TimeDistributed(Dense(output_diminsion,\n",
    "                                                        activation=dense_activation)) \n",
    "        #Interpolation layer\n",
    "        self.interpolation_layer = InterpolationLayer(num_frames=interpolation_frames)\n",
    "        #Locgen dense layer\n",
    "        self.locgen_dense_layer = TimeDistributed(Dense(output_diminsion,\n",
    "                                                        activation=dense_activation)) \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #Glogen calls      \n",
    "        encoder_outputs, state_h, state_c = self.glogen_encoder(inputs)\n",
    "        encoder_states = [state_h, state_c]\n",
    "        output, _, _ = self.glogen_decoder(encoder_outputs, initial_state=encoder_states)\n",
    "        glogen_output = self.glogen_dense_layer(output)\n",
    "\n",
    "        #Interpolation call\n",
    "        interpolated_frames = self.interpolation_layer(glogen_output)\n",
    "        \n",
    "        if self.exclude_locgen :\n",
    "            return interpolated_frames\n",
    "\n",
    "        #Locgen calls\n",
    "        locgen_encoder_outputs, locgen_state_h, locgen_state_c = self.locgen_encoder(interpolated_frames)\n",
    "        locgen_encoder_states = [locgen_state_h, locgen_state_c]\n",
    "        locgen_output, _, _ = self.locgen_decoder(locgen_encoder_outputs, initial_state=locgen_encoder_states)\n",
    "        final_output = self.locgen_dense_layer(locgen_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bVUFJsv3fVYh"
   },
   "outputs": [],
   "source": [
    "class JointLoss() :\n",
    "    \"\"\"\n",
    "    Joint loss class with two weight attributes for two different losses\n",
    "    first one is the loss joint and the second is the loss_motion_flow\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda1=0.5, lambda2=0.5, mmd_kernel='gaussian') :\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.mmd_kernel = mmd_kernel\n",
    "\n",
    "    def loss_joint(self, predicted_sequance_batch, target_sequance_batch) :\n",
    "        \"\"\"\n",
    "        Loss between the joint positions and its corresponding counterparts in the groundtruth\n",
    "        \"\"\"\n",
    "        diff_norm_2 = tf.math.reduce_sum(tf.square(tf.subtract(predicted_sequance_batch, target_sequance_batch)), axis=2)\n",
    "        return tf.reduce_sum(diff_norm_2, axis=1) \n",
    "\n",
    "    def loss_motion_flow(self, predicted_sequance_batch, target_sequance_batch) :\n",
    "        \"\"\"\n",
    "        Loss between the motion flow of predicted sequance and the ground truth\n",
    "        where the motion flow is the euclidean distance between each two consecutive frames\n",
    "        \"\"\"\n",
    "        predictions_tomporal_diffs = tf.experimental.numpy.diff(predicted_sequance_batch, axis=1)\n",
    "        real_tomporal_diffs = tf.experimental.numpy.diff(target_sequance_batch, axis=1)\n",
    "        prediction_motion_flow_diff_norm_2 = tf.reduce_sum(tf.square(tf.subtract(predictions_tomporal_diffs, real_tomporal_diffs)), axis=2)\n",
    "        return tf.reduce_sum(prediction_motion_flow_diff_norm_2, axis=1)\n",
    "\n",
    "\n",
    "    def total_loss(self, target_sequance_batch, predicted_sequance_batch) :\n",
    "        \"\"\"\n",
    "        calculating the total loss through a combination of the joint_loss and motion_flow_loss\n",
    "        \"\"\"\n",
    "        joints_loss = self.loss_joint(predicted_sequance_batch, target_sequance_batch)\n",
    "        motion_flow_loss = self.loss_motion_flow(predicted_sequance_batch, target_sequance_batch)\n",
    "        return self.lambda1*joints_loss + self.lambda2*motion_flow_loss\n",
    "\n",
    "    def custom_sequence_MMD_loss(self, target_sequance_batch, predicted_sequance_batch):\n",
    "        \"\"\"\n",
    "        Calculating the Sequence MMD Loss between prediction and the ground Truth.\n",
    "         Additionally combining the last two dimensions \n",
    "        \"\"\"\n",
    "        mmd_loss = MMD.MMDLoss(kernel=self.mmd_kernel)\n",
    "        total_batches = predicted_sequance_batch.shape[0]\n",
    "        frames_per_batch = predicted_sequance_batch.shape[1] * predicted_sequance_batch.shape[2]\n",
    "        return mmd_loss(tf.reshape(predicted_sequance_batch, [total_batches, frames_per_batch]),\n",
    "                        tf.reshape(target_sequance_batch, [total_batches, frames_per_batch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az25davkJq9Y"
   },
   "source": [
    "## Running experiment with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "labA65KEakkZ"
   },
   "outputs": [],
   "source": [
    "def run_experiment(sampled_dataX, sampled_dataY, learning_rate=0.002, lambda1=0.5,\n",
    "                   lambda2=0.5, use_mse=False, use_MMD=False, metrics=None,\n",
    "                   batch_size=100, epochs=50, validation_split=0.2, activation=\"relu\",\n",
    "                   dropout=0.25, exclude_locgen=False, interpolate_frames = 5) :\n",
    "    \"\"\"\n",
    "    Method takes all hyperparameters as input paramters and returns the model and history as\n",
    "    a result\n",
    "    \"\"\"\n",
    "    glocal_model = GlocalNet(dense_activation=activation, LSTM_dropout=dropout,\n",
    "                             exclude_locgen=exclude_locgen, interpolation_frames = interpolate_frames)\n",
    "    if use_mse :\n",
    "        loss_function = tf.keras.losses.mean_squared_error\n",
    "    elif use_MMD :\n",
    "        loss_function = JointLoss().custom_sequence_MMD_loss\n",
    "    else :\n",
    "        loss_function = JointLoss(lambda1=lambda1, lambda2=lambda2).total_loss\n",
    "\n",
    "    glocal_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                       loss=loss_function, metrics=metrics)\n",
    "    history = glocal_model.fit(sampled_dataX, sampled_dataY,\n",
    "                              batch_size=batch_size,\n",
    "                              epochs=epochs, validation_split=validation_split)\n",
    "    return history, glocal_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTHffB1KrfBy"
   },
   "source": [
    "## Experiment Running for MSE and joint loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQ-XPaUFd4D0",
    "outputId": "bf808cf3-cea2-4283-e53f-4d4e2dbba85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1276/1276 [==============================] - 342s 209ms/step - loss: 106904.7812 - mean_absolute_percentage_error: 56.2039\n",
      "Epoch 2/10\n",
      "1276/1276 [==============================] - 264s 207ms/step - loss: 30513.5723 - mean_absolute_percentage_error: 23.5763\n",
      "Epoch 3/10\n",
      "1276/1276 [==============================] - 265s 208ms/step - loss: 27432.4473 - mean_absolute_percentage_error: 22.4088\n",
      "Epoch 4/10\n",
      "1276/1276 [==============================] - 265s 207ms/step - loss: 27421.8906 - mean_absolute_percentage_error: 22.4447\n",
      "Epoch 5/10\n",
      "1276/1276 [==============================] - 265s 207ms/step - loss: 27422.8105 - mean_absolute_percentage_error: 22.4478\n",
      "Epoch 6/10\n",
      "1276/1276 [==============================] - 266s 208ms/step - loss: 27424.5762 - mean_absolute_percentage_error: 22.4538\n",
      "Epoch 7/10\n",
      "1276/1276 [==============================] - 270s 212ms/step - loss: 27424.1348 - mean_absolute_percentage_error: 22.4491\n",
      "Epoch 8/10\n",
      "1276/1276 [==============================] - 266s 208ms/step - loss: 27424.6250 - mean_absolute_percentage_error: 22.4539\n",
      "Epoch 9/10\n",
      "1276/1276 [==============================] - 266s 209ms/step - loss: 27424.2188 - mean_absolute_percentage_error: 22.4520\n",
      "Epoch 10/10\n",
      "1276/1276 [==============================] - 266s 208ms/step - loss: 27423.6309 - mean_absolute_percentage_error: 22.4506\n"
     ]
    }
   ],
   "source": [
    "history_mse, glocal_model_mse = run_experiment(sampled_dataX, sampled_dataY, epochs=10, \n",
    "                                               use_mse=True, validation_split=0.0,\n",
    "                                               batch_size=20, dropout=0.0,\n",
    "                                               metrics=[tf.keras.losses.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7FQ-HQ4bPVi",
    "outputId": "89e882cb-f5fd-4d5f-d5af-1497efaba172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1276/1276 [==============================] - 319s 210ms/step - loss: 159290336.0000 - mean_absolute_percentage_error: 54.1721\n",
      "Epoch 2/10\n",
      "1276/1276 [==============================] - 267s 209ms/step - loss: 29314212.0000 - mean_absolute_percentage_error: 20.0524\n",
      "Epoch 3/10\n",
      "1276/1276 [==============================] - 584s 458ms/step - loss: 23970064.0000 - mean_absolute_percentage_error: 18.8663\n",
      "Epoch 4/10\n",
      "1276/1276 [==============================] - 689s 540ms/step - loss: 23963464.0000 - mean_absolute_percentage_error: 18.8958\n",
      "Epoch 5/10\n",
      "1276/1276 [==============================] - 308s 241ms/step - loss: 23954730.0000 - mean_absolute_percentage_error: 18.9114\n",
      "Epoch 6/10\n",
      "1276/1276 [==============================] - 275s 216ms/step - loss: 23952396.0000 - mean_absolute_percentage_error: 18.9197\n",
      "Epoch 7/10\n",
      "1276/1276 [==============================] - 277s 217ms/step - loss: 23953500.0000 - mean_absolute_percentage_error: 18.9220\n",
      "Epoch 8/10\n",
      "1276/1276 [==============================] - 275s 215ms/step - loss: 23954034.0000 - mean_absolute_percentage_error: 18.9170\n",
      "Epoch 9/10\n",
      "1276/1276 [==============================] - 276s 217ms/step - loss: 23952172.0000 - mean_absolute_percentage_error: 18.9269\n",
      "Epoch 10/10\n",
      "1276/1276 [==============================] - 275s 215ms/step - loss: 23953862.0000 - mean_absolute_percentage_error: 18.9082\n"
     ]
    }
   ],
   "source": [
    "history_jointLoss, glocal_model_jointLoss = run_experiment(sampled_dataX, sampled_dataY, epochs=10, \n",
    "                                                           lambda1=0.5, lambda2=0.5, validation_split=0.0,\n",
    "                                                           batch_size=20, dropout=0.0,\n",
    "                                                           metrics=[tf.keras.losses.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-ekHZVlrq1o"
   },
   "source": [
    "## Running experiment with MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KayDheMuk7oE",
    "outputId": "4cc7a0d2-53c9-4b41-e24d-dc7990f26a29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1276/1276 [==============================] - 340s 219ms/step - loss: 101695.4688 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 54.8955\n",
      "Epoch 2/10\n",
      "1276/1276 [==============================] - 281s 220ms/step - loss: 21887.8906 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1720\n",
      "Epoch 3/10\n",
      "1276/1276 [==============================] - 304s 238ms/step - loss: 18643.6797 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 19.9711\n",
      "Epoch 4/10\n",
      "1276/1276 [==============================] - 324s 254ms/step - loss: 18629.8809 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0053\n",
      "Epoch 5/10\n",
      "1276/1276 [==============================] - 322s 252ms/step - loss: 18632.0918 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0130\n",
      "Epoch 6/10\n",
      "1276/1276 [==============================] - 290s 227ms/step - loss: 18632.3281 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0231\n",
      "Epoch 7/10\n",
      "1276/1276 [==============================] - 290s 227ms/step - loss: 18633.0547 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0110\n",
      "Epoch 8/10\n",
      "1276/1276 [==============================] - 289s 227ms/step - loss: 18632.6289 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0120\n",
      "Epoch 9/10\n",
      "1276/1276 [==============================] - 300s 235ms/step - loss: 17242.5586 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 19.6462\n",
      "Epoch 10/10\n",
      "1276/1276 [==============================] - 287s 225ms/step - loss: 14217.1201 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7485\n"
     ]
    }
   ],
   "source": [
    "history_mmd, glocal_model_mmd = run_experiment(sampled_dataX, sampled_dataY, epochs=10, \n",
    "                                               use_mse=True, validation_split=0.0,\n",
    "                                               batch_size=20, dropout=0.0,\n",
    "                                               metrics=[JointLoss().custom_sequence_MMD_loss,\n",
    "                                                        tf.keras.losses.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkHRFMEpaXHB",
    "outputId": "ca615ec4-b99d-4f19-b255-eafd3dd12ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1276/1276 [==============================] - 357s 226ms/step - loss: 192679.7656 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 86.6784\n",
      "Epoch 2/15\n",
      "1276/1276 [==============================] - 287s 225ms/step - loss: 121112.6094 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 63.7301\n",
      "Epoch 3/15\n",
      "1276/1276 [==============================] - 286s 224ms/step - loss: 76994.1797 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 45.4688\n",
      "Epoch 4/15\n",
      "1276/1276 [==============================] - 285s 223ms/step - loss: 52473.2070 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 33.6978\n",
      "Epoch 5/15\n",
      "1276/1276 [==============================] - 288s 225ms/step - loss: 41279.4219 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 28.0725\n",
      "Epoch 6/15\n",
      "1276/1276 [==============================] - 286s 224ms/step - loss: 37684.4453 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4507\n",
      "Epoch 7/15\n",
      "1276/1276 [==============================] - 286s 225ms/step - loss: 37085.0430 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.3734\n",
      "Epoch 8/15\n",
      "1276/1276 [==============================] - 284s 222ms/step - loss: 37053.7266 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4477\n",
      "Epoch 9/15\n",
      "1276/1276 [==============================] - 302s 236ms/step - loss: 37053.4375 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4424\n",
      "Epoch 10/15\n",
      "1276/1276 [==============================] - 726s 569ms/step - loss: 37054.0742 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4474\n",
      "Epoch 11/15\n",
      "1276/1276 [==============================] - 578s 453ms/step - loss: 37053.5156 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4484\n",
      "Epoch 12/15\n",
      "1276/1276 [==============================] - 279s 219ms/step - loss: 37053.4102 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4458\n",
      "Epoch 13/15\n",
      "1276/1276 [==============================] - 278s 218ms/step - loss: 37053.5703 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4584\n",
      "Epoch 14/15\n",
      "1276/1276 [==============================] - 279s 219ms/step - loss: 37053.7422 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4381\n",
      "Epoch 15/15\n",
      "1276/1276 [==============================] - 280s 219ms/step - loss: 37054.1172 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4454\n"
     ]
    }
   ],
   "source": [
    "history_low_learning_rate, glocal_low_learning_rate = run_experiment(sampled_dataX, sampled_dataY, epochs=15, \n",
    "                                                                     use_mse=True, learning_rate=0.0005, validation_split=0.0,\n",
    "                                                                     batch_size=20, dropout=0.0,\n",
    "                                                                     metrics=[JointLoss().custom_sequence_MMD_loss, \n",
    "                                                                              tf.keras.losses.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wKSm6QMuGuc",
    "outputId": "e4be73cf-1c86-4ec8-d4d1-36b52558e78f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1276/1276 [==============================] - 340s 222ms/step - loss: 98099.7656 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 54.4614\n",
      "Epoch 2/10\n",
      "1276/1276 [==============================] - 282s 221ms/step - loss: 15513.4570 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 19.9811\n",
      "Epoch 3/10\n",
      "1276/1276 [==============================] - 283s 221ms/step - loss: 12093.3916 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7132\n",
      "Epoch 4/10\n",
      "1276/1276 [==============================] - 281s 220ms/step - loss: 12078.9902 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7472\n",
      "Epoch 5/10\n",
      "1276/1276 [==============================] - 281s 220ms/step - loss: 12080.1641 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7579\n",
      "Epoch 6/10\n",
      "1276/1276 [==============================] - 282s 221ms/step - loss: 12077.4541 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7503\n",
      "Epoch 7/10\n",
      "1276/1276 [==============================] - 283s 222ms/step - loss: 12078.2842 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7561\n",
      "Epoch 8/10\n",
      "1276/1276 [==============================] - 283s 221ms/step - loss: 12080.4824 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7572\n",
      "Epoch 9/10\n",
      "1276/1276 [==============================] - 283s 222ms/step - loss: 12081.6865 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7487\n",
      "Epoch 10/10\n",
      "1276/1276 [==============================] - 282s 221ms/step - loss: 12078.7900 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.7555\n"
     ]
    }
   ],
   "source": [
    "#Running MMD with laplacian kernel\n",
    "history_laplacian, glocal_model_laplacian = run_experiment(sampled_dataX, sampled_dataY, epochs=10, \n",
    "                                                           use_mse=True, validation_split=0.0,\n",
    "                                                           batch_size=20, dropout=0.0,\n",
    "                                                           metrics=[JointLoss(mmd_kernel=\"laplacian\").custom_sequence_MMD_loss,\n",
    "                                                                    tf.keras.losses.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQg05uuoRtEi"
   },
   "source": [
    "## Running Experiment with preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "On6oHsxuRxFS",
    "outputId": "63b6e4bc-0e4d-40ed-97e3-730159a49bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1276/1276 [==============================] - 333s 220ms/step - loss: 102243.4297 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 54.8054\n",
      "Epoch 2/50\n",
      "1276/1276 [==============================] - 283s 221ms/step - loss: 22807.3809 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.3080\n",
      "Epoch 3/50\n",
      "1276/1276 [==============================] - 286s 224ms/step - loss: 19574.1797 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1709\n",
      "Epoch 4/50\n",
      "1276/1276 [==============================] - 293s 230ms/step - loss: 19563.6543 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2226\n",
      "Epoch 5/50\n",
      "1276/1276 [==============================] - 298s 234ms/step - loss: 19563.9805 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2183\n",
      "Epoch 6/50\n",
      "1276/1276 [==============================] - 295s 231ms/step - loss: 19564.6504 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2179\n",
      "Epoch 7/50\n",
      "1276/1276 [==============================] - 279s 218ms/step - loss: 19565.3965 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2242\n",
      "Epoch 8/50\n",
      "1276/1276 [==============================] - 270s 211ms/step - loss: 19876.5586 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.3339\n",
      "Epoch 9/50\n",
      "1276/1276 [==============================] - 271s 212ms/step - loss: 19547.0430 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2048\n",
      "Epoch 10/50\n",
      "1276/1276 [==============================] - 270s 211ms/step - loss: 19547.3691 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2068\n",
      "Epoch 11/50\n",
      "1276/1276 [==============================] - 270s 212ms/step - loss: 19547.6855 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1995\n",
      "Epoch 12/50\n",
      "1276/1276 [==============================] - 276s 216ms/step - loss: 19546.9961 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2056\n",
      "Epoch 13/50\n",
      "1276/1276 [==============================] - 283s 222ms/step - loss: 19547.5449 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2052\n",
      "Epoch 14/50\n",
      "1276/1276 [==============================] - 284s 222ms/step - loss: 19545.5078 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1989\n",
      "Epoch 15/50\n",
      "1276/1276 [==============================] - 283s 222ms/step - loss: 19546.7617 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2123\n",
      "Epoch 16/50\n",
      "1276/1276 [==============================] - 283s 222ms/step - loss: 19547.0703 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2025\n",
      "Epoch 17/50\n",
      "1276/1276 [==============================] - 285s 224ms/step - loss: 19546.5566 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2090\n",
      "Epoch 18/50\n",
      "1276/1276 [==============================] - 285s 223ms/step - loss: 19546.3633 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1997\n",
      "Epoch 19/50\n",
      "1276/1276 [==============================] - 282s 221ms/step - loss: 19546.8613 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1996\n",
      "Epoch 20/50\n",
      "1276/1276 [==============================] - 283s 221ms/step - loss: 19546.1230 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2176\n",
      "Epoch 21/50\n",
      "1276/1276 [==============================] - 280s 219ms/step - loss: 19546.1816 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1951\n",
      "Epoch 22/50\n",
      "1276/1276 [==============================] - 272s 213ms/step - loss: 19547.0098 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2085\n",
      "Epoch 23/50\n",
      "1276/1276 [==============================] - 286s 224ms/step - loss: 19546.0762 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2026\n",
      "Epoch 24/50\n",
      "1276/1276 [==============================] - 312s 244ms/step - loss: 19546.0430 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2044\n",
      "Epoch 25/50\n",
      "1276/1276 [==============================] - 325s 255ms/step - loss: 19548.2695 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1990\n",
      "Epoch 26/50\n",
      "1276/1276 [==============================] - 326s 255ms/step - loss: 19546.4121 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2095\n",
      "Epoch 27/50\n",
      "1276/1276 [==============================] - 324s 254ms/step - loss: 19547.0527 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2036\n",
      "Epoch 28/50\n",
      "1276/1276 [==============================] - 324s 254ms/step - loss: 19547.1445 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2043\n",
      "Epoch 29/50\n",
      "1276/1276 [==============================] - 307s 240ms/step - loss: 19545.5781 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2055\n",
      "Epoch 30/50\n",
      "1276/1276 [==============================] - 285s 224ms/step - loss: 19547.4902 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2063\n",
      "Epoch 31/50\n",
      "1276/1276 [==============================] - 284s 223ms/step - loss: 19546.9629 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1890\n",
      "Epoch 32/50\n",
      "1276/1276 [==============================] - 287s 225ms/step - loss: 19547.8457 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2103\n",
      "Epoch 33/50\n",
      "1276/1276 [==============================] - 289s 227ms/step - loss: 19544.9004 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2049\n",
      "Epoch 34/50\n",
      "1276/1276 [==============================] - 325s 255ms/step - loss: 19548.8594 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2009\n",
      "Epoch 35/50\n",
      "1276/1276 [==============================] - 327s 257ms/step - loss: 19546.0078 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2132\n",
      "Epoch 36/50\n",
      "1276/1276 [==============================] - 324s 254ms/step - loss: 19546.9766 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2006\n",
      "Epoch 37/50\n",
      "1276/1276 [==============================] - 323s 253ms/step - loss: 19546.4336 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1979\n",
      "Epoch 38/50\n",
      "1276/1276 [==============================] - 323s 253ms/step - loss: 19547.1230 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1854\n",
      "Epoch 39/50\n",
      "1276/1276 [==============================] - 328s 257ms/step - loss: 19546.2188 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.1986\n",
      "Epoch 40/50\n",
      "1276/1276 [==============================] - 328s 257ms/step - loss: 19547.2695 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.2008\n",
      "Epoch 41/50\n",
      "1276/1276 [==============================] - 325s 255ms/step - loss: 17998.8457 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.8445\n",
      "Epoch 42/50\n",
      "1276/1276 [==============================] - 331s 260ms/step - loss: 15878.1914 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 16.6782\n",
      "Epoch 43/50\n",
      "1276/1276 [==============================] - 345s 271ms/step - loss: 15459.3555 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 16.0620\n",
      "Epoch 44/50\n",
      "1276/1276 [==============================] - 341s 267ms/step - loss: 15311.7266 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 15.8171\n",
      "Epoch 45/50\n",
      "1276/1276 [==============================] - 342s 268ms/step - loss: 15367.7275 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 15.8945\n",
      "Epoch 46/50\n",
      "1276/1276 [==============================] - 340s 266ms/step - loss: 15052.6592 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 15.5256\n",
      "Epoch 47/50\n",
      "1276/1276 [==============================] - 341s 267ms/step - loss: 14837.5879 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 15.2160\n",
      "Epoch 48/50\n",
      "1276/1276 [==============================] - 340s 267ms/step - loss: 14306.8604 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 14.3320\n",
      "Epoch 49/50\n",
      "1276/1276 [==============================] - 340s 267ms/step - loss: 13901.2764 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 13.6856\n",
      "Epoch 50/50\n",
      "1276/1276 [==============================] - 342s 268ms/step - loss: 13532.5078 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 13.0091\n"
     ]
    }
   ],
   "source": [
    "history_preprocessed, glocal_model_preprocessed = run_experiment(preprocessed_sampled_dataX, preprocessed_sampled_dataY,\n",
    "                                                                 batch_size=20, dropout=0.0,\n",
    "                                                                 epochs=50, use_mse=True, \n",
    "                                                                 metrics=[JointLoss().custom_sequence_MMD_loss,\n",
    "                                                                          tf.keras.losses.mean_absolute_percentage_error], \n",
    "                                                                 validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDY6p981x_s3",
    "outputId": "a0d804dd-fe9b-4534-9fa8-aa22b2ec7f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1276/1276 [==============================] - 319s 192ms/step - loss: 113417.9297 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 58.3448\n",
      "Epoch 2/50\n",
      "1276/1276 [==============================] - 243s 190ms/step - loss: 40860.0938 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 27.8470\n",
      "Epoch 3/50\n",
      "1276/1276 [==============================] - 239s 187ms/step - loss: 37959.8750 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.9271\n",
      "Epoch 4/50\n",
      "1276/1276 [==============================] - 246s 193ms/step - loss: 37954.3594 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.9771\n",
      "Epoch 5/50\n",
      "1276/1276 [==============================] - 225s 176ms/step - loss: 37954.8828 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.9749\n",
      "Epoch 6/50\n",
      "1276/1276 [==============================] - 217s 170ms/step - loss: 37955.5938 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.9748\n",
      "Epoch 7/50\n",
      "1276/1276 [==============================] - 217s 170ms/step - loss: 37957.1797 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.9696\n",
      "Epoch 8/50\n",
      "1276/1276 [==============================] - 217s 170ms/step - loss: 28303.0254 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5673\n",
      "Epoch 9/50\n",
      "1276/1276 [==============================] - 219s 172ms/step - loss: 23438.4668 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 18.8634\n",
      "Epoch 10/50\n",
      "1276/1276 [==============================] - 217s 170ms/step - loss: 21729.9766 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 16.7379\n",
      "Epoch 11/50\n",
      "1276/1276 [==============================] - 216s 169ms/step - loss: 18847.7070 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 14.6365\n",
      "Epoch 12/50\n",
      "1276/1276 [==============================] - 219s 172ms/step - loss: 18526.4785 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 14.0891\n",
      "Epoch 13/50\n",
      "1276/1276 [==============================] - 222s 174ms/step - loss: 18390.1855 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 13.8789\n",
      "Epoch 14/50\n",
      "1276/1276 [==============================] - 215s 169ms/step - loss: 15813.0947 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 13.1241\n",
      "Epoch 15/50\n",
      "1276/1276 [==============================] - 217s 170ms/step - loss: 12763.3154 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.9781\n",
      "Epoch 16/50\n",
      "1276/1276 [==============================] - 296s 232ms/step - loss: 12575.9111 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.7059\n",
      "Epoch 17/50\n",
      "1276/1276 [==============================] - 342s 268ms/step - loss: 12451.5059 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.5129\n",
      "Epoch 18/50\n",
      "1276/1276 [==============================] - 449s 352ms/step - loss: 12364.3340 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.3726\n",
      "Epoch 19/50\n",
      "1276/1276 [==============================] - 389s 305ms/step - loss: 12276.3057 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.2099\n",
      "Epoch 20/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 12205.5840 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.0857\n",
      "Epoch 21/50\n",
      "1276/1276 [==============================] - 192s 150ms/step - loss: 12156.3320 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.9881\n",
      "Epoch 22/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 12138.7412 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.9523\n",
      "Epoch 23/50\n",
      "1276/1276 [==============================] - 191s 149ms/step - loss: 12065.5752 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.8266\n",
      "Epoch 24/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 12034.6846 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.7482\n",
      "Epoch 25/50\n",
      "1276/1276 [==============================] - 191s 149ms/step - loss: 12005.9775 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.6772\n",
      "Epoch 26/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11957.5098 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.5867\n",
      "Epoch 27/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11962.7109 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.5750\n",
      "Epoch 28/50\n",
      "1276/1276 [==============================] - 192s 150ms/step - loss: 11891.8066 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.4259\n",
      "Epoch 29/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11870.8779 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.3663\n",
      "Epoch 30/50\n",
      "1276/1276 [==============================] - 192s 150ms/step - loss: 11860.3916 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.3397\n",
      "Epoch 31/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 11847.7432 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.3070\n",
      "Epoch 32/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11817.0420 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.2401\n",
      "Epoch 33/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11799.4023 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.1967\n",
      "Epoch 34/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 11781.6475 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.1692\n",
      "Epoch 35/50\n",
      "1276/1276 [==============================] - 191s 149ms/step - loss: 11762.4648 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.1356\n",
      "Epoch 36/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11749.0547 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.1054\n",
      "Epoch 37/50\n",
      "1276/1276 [==============================] - 192s 151ms/step - loss: 11727.7217 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.0739\n",
      "Epoch 38/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 11690.7891 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.9924\n",
      "Epoch 39/50\n",
      "1276/1276 [==============================] - 192s 150ms/step - loss: 11720.7637 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.0442\n",
      "Epoch 40/50\n",
      "1276/1276 [==============================] - 193s 151ms/step - loss: 11672.9023 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.9634\n",
      "Epoch 41/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 11677.7705 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.9641\n",
      "Epoch 42/50\n",
      "1276/1276 [==============================] - 190s 149ms/step - loss: 11628.7891 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.8657\n",
      "Epoch 43/50\n",
      "1276/1276 [==============================] - 192s 150ms/step - loss: 11626.8438 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.8511\n",
      "Epoch 44/50\n",
      "1276/1276 [==============================] - 192s 150ms/step - loss: 11604.6279 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.8186\n",
      "Epoch 45/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 11601.2012 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.8135\n",
      "Epoch 46/50\n",
      "1276/1276 [==============================] - 193s 151ms/step - loss: 11568.5381 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.7437\n",
      "Epoch 47/50\n",
      "1276/1276 [==============================] - 191s 150ms/step - loss: 11581.9971 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.7643\n",
      "Epoch 48/50\n",
      "1276/1276 [==============================] - 192s 151ms/step - loss: 11561.6367 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.7231\n",
      "Epoch 49/50\n",
      "1276/1276 [==============================] - 193s 151ms/step - loss: 11558.2842 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.6980\n",
      "Epoch 50/50\n",
      "1276/1276 [==============================] - 194s 152ms/step - loss: 11502.7764 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.6023\n"
     ]
    }
   ],
   "source": [
    "history_interpolation_only, glocal_interpolation_only = run_experiment(preprocessed_sampled_dataX, preprocessed_sampled_dataY,\n",
    "                                                                       batch_size=20, dropout=0.0, exclude_locgen=True,\n",
    "                                                                       epochs=50, use_mse=True, \n",
    "                                                                       metrics=[JointLoss().custom_sequence_MMD_loss,\n",
    "                                                                                tf.keras.losses.mean_absolute_percentage_error], \n",
    "                                                                       validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1276/1276 [==============================] - 156s 101ms/step - loss: 104523.2422 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 56.6736\n",
      "Epoch 2/50\n",
      "1276/1276 [==============================] - 133s 104ms/step - loss: 25759.8691 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 23.7290\n",
      "Epoch 3/50\n",
      "1276/1276 [==============================] - 132s 103ms/step - loss: 22486.5449 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4776\n",
      "Epoch 4/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 22474.7441 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5231\n",
      "Epoch 5/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 22474.8770 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5234\n",
      "Epoch 6/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 22476.1328 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5247\n",
      "Epoch 7/50\n",
      "1276/1276 [==============================] - 135s 105ms/step - loss: 22473.2793 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5240\n",
      "Epoch 8/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 22472.5410 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5158\n",
      "Epoch 9/50\n",
      "1276/1276 [==============================] - 131s 102ms/step - loss: 22470.8340 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5200\n",
      "Epoch 10/50\n",
      "1276/1276 [==============================] - 131s 102ms/step - loss: 22470.7285 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5165\n",
      "Epoch 11/50\n",
      "1276/1276 [==============================] - 131s 102ms/step - loss: 22469.5898 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5173\n",
      "Epoch 12/50\n",
      "1276/1276 [==============================] - 132s 103ms/step - loss: 22467.1934 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.5068\n",
      "Epoch 13/50\n",
      "1276/1276 [==============================] - 131s 103ms/step - loss: 22441.7637 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4901\n",
      "Epoch 14/50\n",
      "1276/1276 [==============================] - 131s 103ms/step - loss: 22441.6133 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4943\n",
      "Epoch 15/50\n",
      "1276/1276 [==============================] - 131s 103ms/step - loss: 22440.2832 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4888\n",
      "Epoch 16/50\n",
      "1276/1276 [==============================] - 131s 103ms/step - loss: 22438.7812 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4859\n",
      "Epoch 17/50\n",
      "1276/1276 [==============================] - 132s 103ms/step - loss: 22440.4395 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4937\n",
      "Epoch 18/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 22439.0664 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4896\n",
      "Epoch 19/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 22437.8750 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4905\n",
      "Epoch 20/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 22437.5645 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.4863\n",
      "Epoch 21/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 20145.4512 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.8837\n",
      "Epoch 22/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 18033.2949 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.2767\n",
      "Epoch 23/50\n",
      "1276/1276 [==============================] - 131s 103ms/step - loss: 18024.9238 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.2952\n",
      "Epoch 24/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 18026.7363 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.2779\n",
      "Epoch 25/50\n",
      "1276/1276 [==============================] - 130s 102ms/step - loss: 18029.1055 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.2630\n",
      "Epoch 26/50\n",
      "1276/1276 [==============================] - 131s 102ms/step - loss: 17861.1211 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1685\n",
      "Epoch 27/50\n",
      "1276/1276 [==============================] - 131s 103ms/step - loss: 14890.9375 - custom_sequence_MMD_loss: 0.0408 - mean_absolute_percentage_error: 19.4252\n",
      "Epoch 28/50\n",
      "1276/1276 [==============================] - 133s 104ms/step - loss: 6667.2158 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 14.4836\n",
      "Epoch 29/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 5572.4810 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 13.1754\n",
      "Epoch 30/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 5312.6616 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 12.8564\n",
      "Epoch 31/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 5260.6973 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 12.7664\n",
      "Epoch 32/50\n",
      "1276/1276 [==============================] - 135s 105ms/step - loss: 5008.2544 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 12.4088\n",
      "Epoch 33/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 4269.0679 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 11.2798\n",
      "Epoch 34/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 4397.8071 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 11.4716\n",
      "Epoch 35/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3816.6189 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 10.4905\n",
      "Epoch 36/50\n",
      "1276/1276 [==============================] - 135s 105ms/step - loss: 3637.5239 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 10.1216\n",
      "Epoch 37/50\n",
      "1276/1276 [==============================] - 134s 105ms/step - loss: 3587.5054 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 10.0329\n",
      "Epoch 38/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3515.2883 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.8918\n",
      "Epoch 39/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3517.3398 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.8980\n",
      "Epoch 40/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3480.8083 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.8334\n",
      "Epoch 41/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3456.3469 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.7928\n",
      "Epoch 42/50\n",
      "1276/1276 [==============================] - 136s 106ms/step - loss: 3365.3809 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.6541\n",
      "Epoch 43/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3339.9333 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.6366\n",
      "Epoch 44/50\n",
      "1276/1276 [==============================] - 136s 106ms/step - loss: 3272.6724 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.5626\n",
      "Epoch 45/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3198.0208 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.4357\n",
      "Epoch 46/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3172.9148 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.4253\n",
      "Epoch 47/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 3091.6167 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.2885\n",
      "Epoch 48/50\n",
      "1276/1276 [==============================] - 136s 106ms/step - loss: 3033.7979 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.2228\n",
      "Epoch 49/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 2944.5581 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 9.0871\n",
      "Epoch 50/50\n",
      "1276/1276 [==============================] - 135s 106ms/step - loss: 2811.3049 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.8767\n"
     ]
    }
   ],
   "source": [
    "history_preprocessed, glocal_model_preprocessed = run_experiment(preprocessed_downsampled_dataX, preprocessed_downsampled_dataY,\n",
    "                                                                 batch_size=20, dropout=0.0,\n",
    "                                                                 epochs=50, use_mse=True, \n",
    "                                                                 metrics=[JointLoss().custom_sequence_MMD_loss,\n",
    "                                                                          tf.keras.losses.mean_absolute_percentage_error], \n",
    "                                                                 validation_split=0.0, interpolate_frames = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1276/1276 [==============================] - 106s 64ms/step - loss: 102362.4844 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 55.6589\n",
      "Epoch 2/50\n",
      "1276/1276 [==============================] - 83s 65ms/step - loss: 23386.0957 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 22.3700\n",
      "Epoch 3/50\n",
      "1276/1276 [==============================] - 83s 65ms/step - loss: 20204.5078 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1436\n",
      "Epoch 4/50\n",
      "1276/1276 [==============================] - 83s 65ms/step - loss: 20193.9922 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1928\n",
      "Epoch 5/50\n",
      "1276/1276 [==============================] - 83s 65ms/step - loss: 20195.3789 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1889\n",
      "Epoch 6/50\n",
      "1276/1276 [==============================] - 82s 64ms/step - loss: 20195.5820 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1916\n",
      "Epoch 7/50\n",
      "1276/1276 [==============================] - 84s 66ms/step - loss: 20195.6055 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.1882\n",
      "Epoch 8/50\n",
      "1276/1276 [==============================] - 84s 66ms/step - loss: 18607.9883 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.7833\n",
      "Epoch 9/50\n",
      "1276/1276 [==============================] - 81s 64ms/step - loss: 15204.7100 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 19.4427\n",
      "Epoch 10/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 12606.2285 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 17.0080\n",
      "Epoch 11/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 11666.5479 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 15.7348\n",
      "Epoch 12/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 10777.0957 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 14.3562\n",
      "Epoch 13/50\n",
      "1276/1276 [==============================] - 77s 61ms/step - loss: 10041.6699 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 13.1581\n",
      "Epoch 14/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 9787.0840 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 12.6983\n",
      "Epoch 15/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 9669.6133 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 12.5054\n",
      "Epoch 16/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 9502.6162 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 12.2698\n",
      "Epoch 17/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 9080.1416 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.8266\n",
      "Epoch 18/50\n",
      "1276/1276 [==============================] - 77s 61ms/step - loss: 7501.6494 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.3601\n",
      "Epoch 19/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 7291.7598 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.0343\n",
      "Epoch 20/50\n",
      "1276/1276 [==============================] - 77s 61ms/step - loss: 7176.9175 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.8173\n",
      "Epoch 21/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 7074.4771 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.6200\n",
      "Epoch 22/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6989.7861 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.4779\n",
      "Epoch 23/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6875.1606 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.2823\n",
      "Epoch 24/50\n",
      "1276/1276 [==============================] - 77s 61ms/step - loss: 6749.9565 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 9.0668\n",
      "Epoch 25/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6675.3506 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.9258\n",
      "Epoch 26/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6588.8413 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.7657\n",
      "Epoch 27/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6535.8242 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.6537\n",
      "Epoch 28/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6479.0879 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.5269\n",
      "Epoch 29/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6450.4966 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.4526\n",
      "Epoch 30/50\n",
      "1276/1276 [==============================] - 77s 60ms/step - loss: 6412.5405 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.3667\n",
      "Epoch 31/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6367.7637 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.2699\n",
      "Epoch 32/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6315.1694 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.1687\n",
      "Epoch 33/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6309.7480 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.1503\n",
      "Epoch 34/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6253.3110 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 8.0256\n",
      "Epoch 35/50\n",
      "1276/1276 [==============================] - 79s 62ms/step - loss: 6231.1162 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.9793\n",
      "Epoch 36/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6199.4092 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.9049\n",
      "Epoch 37/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6175.4951 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.8599\n",
      "Epoch 38/50\n",
      "1276/1276 [==============================] - 77s 61ms/step - loss: 6157.4512 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.8256\n",
      "Epoch 39/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6112.8350 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.7254\n",
      "Epoch 40/50\n",
      "1276/1276 [==============================] - 77s 61ms/step - loss: 6095.4951 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.6849\n",
      "Epoch 41/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6083.7158 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.6618\n",
      "Epoch 42/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6049.3682 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.5797\n",
      "Epoch 43/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6045.3330 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.5717\n",
      "Epoch 44/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 6014.7983 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.4996\n",
      "Epoch 45/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 5999.8833 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.4664\n",
      "Epoch 46/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 5990.2646 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.4427\n",
      "Epoch 47/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 5974.2520 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.4076\n",
      "Epoch 48/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 5958.9116 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.3671\n",
      "Epoch 49/50\n",
      "1276/1276 [==============================] - 78s 61ms/step - loss: 5932.5391 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.2964\n",
      "Epoch 50/50\n",
      "1276/1276 [==============================] - 79s 62ms/step - loss: 5914.9751 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 7.2483\n"
     ]
    }
   ],
   "source": [
    "history_interpolation_only, glocal_interpolation_only = run_experiment(preprocessed_downsampled_dataX, preprocessed_downsampled_dataY,\n",
    "                                                                       batch_size=20, dropout=0.0, exclude_locgen=True,\n",
    "                                                                       epochs=50, use_mse=True, \n",
    "                                                                       metrics=[JointLoss().custom_sequence_MMD_loss,\n",
    "                                                                                tf.keras.losses.mean_absolute_percentage_error], \n",
    "                                                                       validation_split=0.0, interpolate_frames = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnqZvA_2S7xD"
   },
   "outputs": [],
   "source": [
    "predictions = glocal_model_preprocessed(sampled_dataX[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "twUcXJOzrSSF"
   },
   "outputs": [],
   "source": [
    "predictions = glocal_interpolation_only(sampled_dataX[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Ce3ilE9P2CuD"
   },
   "outputs": [],
   "source": [
    "predictions_sum = np.sum(np.reshape(predictions, (1000, 50*64)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "KIDvGYUVtTYx",
    "outputId": "ea1dddd2-0587-4901-8050-5c82ac7456e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb8dd9afd10>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,1000), predictions_sum)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "snGEPtNOKLvg",
    "KTHffB1KrfBy",
    "H-ekHZVlrq1o"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
