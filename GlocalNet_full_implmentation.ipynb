{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6oWUCJCnPmT",
        "outputId": "ff69467f-8448-4bca-9677-0f6de49a4388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import Model as Model_\n",
        "from tensorflow.keras.layers import Input, ReLU, LSTM, Dense, TimeDistributed, Bidirectional, Normalization, GaussianNoise \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print(tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need only to be used with google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1wLcoRN_q6H",
        "outputId": "2539f137-5031-49c5-97e6-58097f137e1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_remediation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVYkmolC_bDI",
        "outputId": "343f646f-7dab-4c4d-eb9f-6b4f3f26e0d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_model_remediation\n",
            "  Downloading tensorflow_model_remediation-0.1.7.1-py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_remediation) (1.3.5)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_remediation) (0.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_remediation) (0.3.5.1)\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_remediation) (2.8.2+zzzcolab20220719082949)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.48.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (2.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->tensorflow_model_remediation) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->tensorflow_model_remediation) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.0.0->tensorflow_model_remediation) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (3.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->tensorflow_model_remediation) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_model_remediation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_model_remediation) (2022.2.1)\n",
            "Installing collected packages: mock, tensorflow-model-remediation\n",
            "Successfully installed mock-4.0.3 tensorflow-model-remediation-0.1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_remediation.min_diff.losses.mmd_loss as MMD\n",
        "import tensorflow_model_remediation.min_diff.losses.adjusted_mmd_loss as adjustedMMD"
      ],
      "metadata": {
        "id": "ueL6mTdUwhcp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ikRIhsrrnhlH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "class Dataset_Preprocessing:\n",
        "    def __init__(self, dir_path, include_dimension = 2, sample_size = 50, total_classes = 17, datatype = 'float32'):\n",
        "        \n",
        "        #Dataset Directory path\n",
        "        self.dir_path = dir_path\n",
        "        \n",
        "        #Which Dimension file to include, possible values: 2 and 3\n",
        "        self.include_dimension = include_dimension\n",
        "        \n",
        "        #Total frames in one Sample\n",
        "        self.sample_size = sample_size\n",
        "        \n",
        "        #Default Datatype for all the samples\n",
        "        self.datatype = datatype\n",
        "        \n",
        "        #Activity classes to include\n",
        "        self.classes = ['SittingDown', 'Walking', 'Directions', 'Discussion', 'Sitting', 'Phoning', 'Eating', 'Posing', 'Greeting', 'Smoking']\n",
        "        \n",
        "        #Total activity classes\n",
        "        self.total_classes = len(self.classes)\n",
        "        \n",
        "        #Subject Folders names in the Dataset\n",
        "        self.internal_folders = ['S1', 'S5','S6','S7','S8','S9','S11']\n",
        "    \n",
        "    def read_dataset(self):\n",
        "        try:\n",
        "            #Contains all the different activity vectors\n",
        "            activity_vector = {}\n",
        "            \n",
        "            #Contains the overall dataset\n",
        "            sampled_data = None\n",
        "            \n",
        "            #Based on dimensions, which folder to use for extracting the dataset files\n",
        "            data_folder = 'Poses_D2_Positions' if self.include_dimension == 2 else 'Poses_D3_Positions'\n",
        "            \n",
        "            #Checking if the dataset path is valid\n",
        "            if not os.path.exists(self.dir_path):\n",
        "                print('The Data Directory Does not Exist!')\n",
        "                return None\n",
        "\n",
        "            #Iterating over all the subject folders\n",
        "            for fld in self.internal_folders:\n",
        "                #Iterating for each file in the specified folder\n",
        "                for file in os.listdir(os.path.join(self.dir_path, fld, data_folder)):\n",
        "                    #Extracting the activity from the filename\n",
        "                    activity = self.__extract_activity(file)\n",
        "                    \n",
        "                    if activity not in self.classes:\n",
        "                        continue\n",
        "                    \n",
        "                    #Reading the CSV file using Pandas\n",
        "                    data = pd.read_csv(os.path.join(self.dir_path, fld, data_folder, file), header=None)\n",
        "\n",
        "                    #Formulating the activity vector using one hot encoding\n",
        "                    if activity not in activity_vector:\n",
        "                        total_keys = len(activity_vector.keys())\n",
        "                        activity_vector[activity] = np.zeros(self.total_classes)\n",
        "                        activity_vector[activity][total_keys] = 1\n",
        "                    vector = activity_vector[activity]\n",
        "                    \n",
        "                    #Sampling the dataset\n",
        "                    grouped_sample = self.__group_samples(data, self.sample_size, vector)\n",
        "                    sampled_data = grouped_sample if sampled_data is None else np.append(sampled_data, grouped_sample, axis=0)\n",
        "            \n",
        "            #Changing the Datatype\n",
        "            sampled_data = sampled_data.astype(self.datatype)\n",
        "            \n",
        "            return sampled_data\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    \n",
        "    def __extract_activity(self, filename):\n",
        "        try:\n",
        "            #Extracting the filename and excluding the extension\n",
        "            name = os.path.splitext(filename)[0]\n",
        "            \n",
        "            #Substituting the empty string with characters other than english alphabets\n",
        "            activity = re.sub('[^A-Za-z]+' , '' , name)\n",
        "            return activity\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    \n",
        "    def __group_samples(self, dataset, sample_size, activity):\n",
        "        try:\n",
        "            #Checking if the dataset is a Pandas Dataframe\n",
        "            if not isinstance(dataset, pd.DataFrame):\n",
        "                print('Expecting Pandas Dataframe, but got {}'.format(type(dataset)))\n",
        "                return None\n",
        "            \n",
        "            #Appending activity class to each row in the dataset\n",
        "            dataset = pd.concat([dataset, pd.DataFrame(np.tile(activity, (dataset.shape[0],1)))], axis=1)\n",
        "            \n",
        "            #Reshaping the dataset into sample batches\n",
        "            total_samples = dataset.shape[0]//sample_size\n",
        "            total_features = dataset.shape[1]\n",
        "            grouped_rows = dataset.to_numpy()[:total_samples*self.sample_size].reshape((-1,self.sample_size, total_features))\n",
        "            \n",
        "            return grouped_rows\n",
        "        except Exception as e:\n",
        "            print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f8PgK1UVnkrw"
      },
      "outputs": [],
      "source": [
        "#For long term prediction, we need a sample size of 60(10 frames input sequance, 50 frames predicted sequance)\n",
        "sampled_data = Dataset_Preprocessing('/content/drive/MyDrive/Colab Notebooks/H3.6csv', sample_size=60).read_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting dataset to features and labels"
      ],
      "metadata": {
        "id": "ZJ4Vt5JFJYLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8nABIG0rnxl_"
      },
      "outputs": [],
      "source": [
        "def split_to_features_labels(dataset, input_sequance_size=10) :\n",
        "    \"\"\"\n",
        "    Function for splitting the data into features(with sequance size=iput_sequance_size)\n",
        "    and labels which should be the remainder of the sample length \n",
        "    \"\"\"\n",
        "    assert input_sequance_size < dataset.shape[1], f\"input sequance should be smaller than the total sample size\"\n",
        "    features = dataset[:, np.s_[0:input_sequance_size], :]\n",
        "    labels = dataset[:,np.s_[input_sequance_size:], :64]\n",
        "    \n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To make the data divisible for batch size of 20\n",
        "total_batches = sampled_data.shape[0]\n",
        "sampled_data = sampled_data[:total_batches-(total_batches%20)]"
      ],
      "metadata": {
        "id": "lw6Tvviol_Ch"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h6bSQTwdn2Fo"
      },
      "outputs": [],
      "source": [
        "sampled_dataX, sampled_dataY = split_to_features_labels(sampled_data, input_sequance_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVXQiscVn4O2",
        "outputId": "16b74b2e-2707-4115-943d-dc1b320fc83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Samples: 25520\n",
            "Total Frames: 50\n",
            "Total Features: 64\n"
          ]
        }
      ],
      "source": [
        "print('Total Samples: {}'.format(sampled_dataY.shape[0]))\n",
        "print('Total Frames: {}'.format(sampled_dataY.shape[1]))\n",
        "print('Total Features: {}'.format(sampled_dataY.shape[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding Preprocessing steps to improve model performance and robustness"
      ],
      "metadata": {
        "id": "snGEPtNOKLvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downsampling to be implemented\n",
        "def preprocess_data(sampled_dataX, sampled_dataY, normalize=True, add_noise=True\n",
        "                    , downsample= False , stddev=0.05) :\n",
        "    \"\"\"\n",
        "    Function to preprocess data by normalizing input features and adding guassian\n",
        "    noise to increase model robustness\n",
        "    \"\"\"  \n",
        "    if normalize :\n",
        "      sampled_dataX =  tf.keras.utils.normalize(sampled_dataX, axis=2)\n",
        "    if add_noise :\n",
        "      guassian_noise_layer = tf.keras.layers.GaussianNoise(stddev=stddev)\n",
        "      sampled_dataX = guassian_noise_layer(sampled_dataX)\n",
        "    return sampled_dataX, sampled_dataY"
      ],
      "metadata": {
        "id": "VzjeqMm1KNjQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sampled_dataX, preprocessed_sampled_dataY = preprocess_data(sampled_dataX, sampled_dataY) "
      ],
      "metadata": {
        "id": "4bR0E_RfMlHg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sampled_dataY.shape == sampled_dataY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAi8XtxJmMBu",
        "outputId": "feb03f31-dfd8-4022-869b-881427dcac94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining different components of the model"
      ],
      "metadata": {
        "id": "kwCrXubfJka4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QsfCMT-0zRTs"
      },
      "outputs": [],
      "source": [
        "class InterpolationLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom interpolation layer extending the keras layer class\n",
        "    it has one attribute num_frames to be interpolated between each two consecutive \n",
        "    timesteps\n",
        "    it has one main function interpolateFrames  \n",
        "    \"\"\"\n",
        "  \n",
        "    def __init__(self, num_frames=5):\n",
        "        super(InterpolationLayer, self).__init__()\n",
        "        self.num_frames = num_frames\n",
        "       \n",
        "    def interpolateFrames(self, inputs):\n",
        "      \"\"\"\n",
        "      Takes input tensors of shape(batch_size, timesteps, features)\n",
        "      returns interpolated frames with shape(batch_size, timesteps*num_frames, features)\n",
        "      \"\"\"\n",
        "      batch_size = inputs.shape[0]\n",
        "      timesteps = inputs.shape[1]\n",
        "      features = inputs.shape[2]\n",
        "      interpolated_frames = tf.zeros([0, features])\n",
        "\n",
        "      for batch in range(batch_size) :\n",
        "        for t in range(timesteps) :\n",
        "          for j in range(self.num_frames) :\n",
        "            X_i0 = inputs[batch, t]\n",
        "            if(t == timesteps-1) :\n",
        "              X_i1 = inputs[batch, t]\n",
        "            else :  \n",
        "              X_i1 = inputs[batch, t+1]\n",
        "            alpha_j = j/self.num_frames\n",
        "            current_frame = alpha_j*X_i0 + (1-alpha_j)*X_i1\n",
        "            current_frame = tf.reshape(current_frame, [1, features])\n",
        "            interpolated_frames = tf.concat((interpolated_frames, current_frame), axis=0)\n",
        "            \n",
        "      interpolated_frames = tf.reshape(interpolated_frames,\n",
        "                                       [batch_size, (timesteps)*self.num_frames, features])\n",
        "      return interpolated_frames\n",
        "\n",
        "    def call(self, inputs):\n",
        "      return self.interpolateFrames(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "7PIJXvLaaEvY"
      },
      "outputs": [],
      "source": [
        "class GlocalNet(Model_):\n",
        "    \"\"\"\n",
        "    A full GlocalNet implementation include the three main stages\n",
        "    Glogen generating initial sparse frames\n",
        "    Interpolation layer generating dense frames from Glogen output\n",
        "    Locgen generating the final output by smoothing the interpolated frames\n",
        "    \"\"\"\n",
        "    def __init__(self, enocder_hidden_state=200, decoder_hidden_state=200, \n",
        "                 output_diminsion=64, LSTM_dropout=0.25, dense_activation='relu',\n",
        "                 interpolation_frames=5, exclude_locgen=False):\n",
        "        super(GlocalNet, self).__init__()\n",
        "        self.exclude_locgen = exclude_locgen\n",
        "        #Glogen layers\n",
        "        self.glogen_encoder = LSTM(enocder_hidden_state, return_state=True\n",
        "                                   , return_sequences=True, dropout=LSTM_dropout)\n",
        "        self.glogen_decoder = LSTM(decoder_hidden_state, return_sequences=True,\n",
        "                                   return_state=True, dropout=LSTM_dropout)\n",
        "        #Locgen layers\n",
        "        self.locgen_encoder = LSTM(enocder_hidden_state, return_sequences=True,\n",
        "                                   return_state=True, dropout=LSTM_dropout)\n",
        "        self.locgen_decoder = LSTM(decoder_hidden_state, return_sequences=True,\n",
        "                                   return_state=True, dropout=LSTM_dropout)\n",
        "        #Glogen dense layer\n",
        "        self.glogen_dense_layer = TimeDistributed(Dense(output_diminsion,\n",
        "                                                        activation=dense_activation)) \n",
        "        #Interpolation layer\n",
        "        self.interpolation_layer = InterpolationLayer(num_frames=interpolation_frames)\n",
        "        #Locgen dense layer\n",
        "        self.locgen_dense_layer = TimeDistributed(Dense(output_diminsion,\n",
        "                                                        activation=dense_activation)) \n",
        "        \n",
        "    def call(self, inputs):\n",
        "        #Glogen calls      \n",
        "        encoder_outputs, state_h, state_c = self.glogen_encoder(inputs)\n",
        "        encoder_states = [state_h, state_c]\n",
        "        output, _, _ = self.glogen_decoder(encoder_outputs, initial_state=encoder_states)\n",
        "        glogen_output = self.glogen_dense_layer(output)\n",
        "\n",
        "        #Interpolation call\n",
        "        interpolated_frames = self.interpolation_layer(glogen_output)\n",
        "        \n",
        "        if self.exclude_locgen :\n",
        "          return interpolated_frames\n",
        "\n",
        "        #Locgen calls\n",
        "        locgen_encoder_outputs, locgen_state_h, locgen_state_c = self.locgen_encoder(interpolated_frames)\n",
        "        locgen_encoder_states = [locgen_state_h, locgen_state_c]\n",
        "        locgen_output, _, _ = self.locgen_decoder(locgen_encoder_outputs, initial_state=locgen_encoder_states)\n",
        "        final_output = self.locgen_dense_layer(locgen_output)\n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bVUFJsv3fVYh"
      },
      "outputs": [],
      "source": [
        "class JointLoss() :\n",
        "    \"\"\"\n",
        "    Joint loss class with two weight attributes for two different losses\n",
        "    first one is the loss joint and the second is the loss_motion_flow\n",
        "    \"\"\"\n",
        "    def __init__(self, lambda1=0.5, lambda2=0.5, mmd_kernel='gaussian') :\n",
        "        self.lambda1 = lambda1\n",
        "        self.lambda2 = lambda2\n",
        "        self.mmd_kernel = mmd_kernel\n",
        "\n",
        "    def loss_joint(self, predicted_sequance_batch, target_sequance_batch) :\n",
        "        \"\"\"\n",
        "        Loss between the joint positions and its corresponding counterparts in the groundtruth\n",
        "        \"\"\"\n",
        "        diff_norm_2 = tf.math.reduce_sum(tf.square(tf.subtract(predicted_sequance_batch, target_sequance_batch)), axis=2)\n",
        "        return tf.reduce_sum(diff_norm_2, axis=1) \n",
        "\n",
        "    def loss_motion_flow(self, predicted_sequance_batch, target_sequance_batch) :\n",
        "        \"\"\"\n",
        "        Loss between the motion flow of predicted sequance and the ground truth\n",
        "        where the motion flow is the euclidean distance between each two consecutive frames\n",
        "        \"\"\"\n",
        "        predictions_tomporal_diffs = tf.experimental.numpy.diff(predicted_sequance_batch, axis=1)\n",
        "        real_tomporal_diffs = tf.experimental.numpy.diff(target_sequance_batch, axis=1)\n",
        "        prediction_motion_flow_diff_norm_2 = tf.reduce_sum(tf.square(tf.subtract(predictions_tomporal_diffs, real_tomporal_diffs)), axis=2)\n",
        "        return tf.reduce_sum(prediction_motion_flow_diff_norm_2, axis=1)\n",
        "\n",
        "\n",
        "    def total_loss(self, target_sequance_batch, predicted_sequance_batch) :\n",
        "        \"\"\"\n",
        "        calculating the total loss through a combination of the joint_loss and motion_flow_loss\n",
        "        \"\"\"\n",
        "        joints_loss = self.loss_joint(predicted_sequance_batch, target_sequance_batch)\n",
        "        motion_flow_loss = self.loss_motion_flow(predicted_sequance_batch, target_sequance_batch)\n",
        "        return self.lambda1*joints_loss + self.lambda2*motion_flow_loss\n",
        "\n",
        "    def custom_sequence_MMD_loss(self, target_sequance_batch, predicted_sequance_batch):\n",
        "        \"\"\"\n",
        "        Calculating the Sequence MMD Loss between prediction and the ground Truth.\n",
        "         Additionally combining the last two dimensions \n",
        "        \"\"\"\n",
        "        mmd_loss = MMD.MMDLoss(kernel=self.mmd_kernel)\n",
        "        total_batches = predicted_sequance_batch.shape[0]\n",
        "        frames_per_batch = predicted_sequance_batch.shape[1] * predicted_sequance_batch.shape[2]\n",
        "        return mmd_loss(tf.reshape(predicted_sequance_batch, [total_batches, frames_per_batch]),\n",
        "                        tf.reshape(target_sequance_batch, [total_batches, frames_per_batch]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Running experiment with different hyperparameters"
      ],
      "metadata": {
        "id": "Az25davkJq9Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "labA65KEakkZ"
      },
      "outputs": [],
      "source": [
        "def run_experiment(sampled_dataX, sampled_dataY, learning_rate=0.002, lambda1=0.5,\n",
        "                   lambda2=0.5, use_mse=False, use_MMD=False, metrics=None,\n",
        "                   batch_size=100, epochs=50, validation_split=0.2, activation=\"relu\",\n",
        "                   dropout=0.25, exclude_locgen=False) :\n",
        "    \"\"\"\n",
        "    Method takes all hyperparameters as input paramters and returns the model and history as\n",
        "    a result\n",
        "    \"\"\"\n",
        "    glocal_model = GlocalNet(dense_activation=activation, LSTM_dropout=dropout,\n",
        "                             exclude_locgen=exclude_locgen)\n",
        "    if use_mse :\n",
        "        loss_function = tf.keras.losses.mean_squared_error\n",
        "    elif use_MMD :\n",
        "        loss_function = JointLoss().custom_sequence_MMD_loss\n",
        "    else :\n",
        "        loss_function = JointLoss(lambda1=lambda1, lambda2=lambda2).total_loss\n",
        "\n",
        "    glocal_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                       loss=loss_function, metrics=metrics)\n",
        "    history = glocal_model.fit(sampled_dataX, sampled_dataY,\n",
        "                              batch_size=batch_size,\n",
        "                              epochs=epochs, validation_split=validation_split)\n",
        "    return history, glocal_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTHffB1KrfBy"
      },
      "source": [
        "## Experiment Running for MSE and joint loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ-XPaUFd4D0",
        "outputId": "bf808cf3-cea2-4283-e53f-4d4e2dbba85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "255/255 [==============================] - 415s 240ms/step - loss: 197673.3438 - mean_absolute_percentage_error: 88.2866\n",
            "Epoch 2/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 128336.4766 - mean_absolute_percentage_error: 67.4349\n",
            "Epoch 3/10\n",
            "255/255 [==============================] - 62s 243ms/step - loss: 82020.9609 - mean_absolute_percentage_error: 50.1100\n",
            "Epoch 4/10\n",
            "255/255 [==============================] - 64s 250ms/step - loss: 52302.0547 - mean_absolute_percentage_error: 37.0668\n",
            "Epoch 5/10\n",
            "255/255 [==============================] - 61s 240ms/step - loss: 34254.2656 - mean_absolute_percentage_error: 28.3228\n",
            "Epoch 6/10\n",
            "255/255 [==============================] - 61s 241ms/step - loss: 23976.3828 - mean_absolute_percentage_error: 23.0670\n",
            "Epoch 7/10\n",
            "255/255 [==============================] - 63s 245ms/step - loss: 18552.9414 - mean_absolute_percentage_error: 20.3186\n",
            "Epoch 8/10\n",
            "255/255 [==============================] - 61s 241ms/step - loss: 15939.6357 - mean_absolute_percentage_error: 19.0722\n",
            "Epoch 9/10\n",
            "255/255 [==============================] - 62s 242ms/step - loss: 14812.7559 - mean_absolute_percentage_error: 18.6462\n",
            "Epoch 10/10\n",
            "255/255 [==============================] - 62s 245ms/step - loss: 14385.7510 - mean_absolute_percentage_error: 18.5867\n"
          ]
        }
      ],
      "source": [
        "history_mse, glocal_model_mse = run_experiment(epochs=10, use_mse=True, metrics=[tf.keras.losses.mean_absolute_percentage_error])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7FQ-HQ4bPVi",
        "outputId": "89e882cb-f5fd-4d5f-d5af-1497efaba172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "255/255 [==============================] - 419s 248ms/step - loss: 318235136.0000 - mean_absolute_percentage_error: 88.8408\n",
            "Epoch 2/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 209204064.0000 - mean_absolute_percentage_error: 68.7124\n",
            "Epoch 3/10\n",
            "255/255 [==============================] - 64s 252ms/step - loss: 136290848.0000 - mean_absolute_percentage_error: 52.0030\n",
            "Epoch 4/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 89421984.0000 - mean_absolute_percentage_error: 39.3298\n",
            "Epoch 5/10\n",
            "255/255 [==============================] - 64s 251ms/step - loss: 60899012.0000 - mean_absolute_percentage_error: 30.7696\n",
            "Epoch 6/10\n",
            "255/255 [==============================] - 65s 254ms/step - loss: 44627976.0000 - mean_absolute_percentage_error: 25.5873\n",
            "Epoch 7/10\n",
            "255/255 [==============================] - 64s 250ms/step - loss: 36028060.0000 - mean_absolute_percentage_error: 22.8682\n",
            "Epoch 8/10\n",
            "255/255 [==============================] - 64s 251ms/step - loss: 31884704.0000 - mean_absolute_percentage_error: 21.6249\n",
            "Epoch 9/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 30101348.0000 - mean_absolute_percentage_error: 21.2003\n",
            "Epoch 10/10\n",
            "255/255 [==============================] - 64s 252ms/step - loss: 29427098.0000 - mean_absolute_percentage_error: 21.1448\n"
          ]
        }
      ],
      "source": [
        "history_jointLoss, glocal_model_jointLoss = run_experiment(epochs=10, lambda1=0.5, lambda2=0.5, metrics=[tf.keras.losses.mean_absolute_percentage_error])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-ekHZVlrq1o"
      },
      "source": [
        "## Running experiment with MMD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KayDheMuk7oE",
        "outputId": "4cc7a0d2-53c9-4b41-e24d-dc7990f26a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "204/204 [==============================] - 495s 663ms/step - loss: 205974.6562 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 90.6578 - val_loss: 171432.6875 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 81.5120\n",
            "Epoch 2/10\n",
            "204/204 [==============================] - 56s 273ms/step - loss: 145359.6406 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 73.3579 - val_loss: 120135.9531 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 65.2601\n",
            "Epoch 3/10\n",
            "204/204 [==============================] - 55s 270ms/step - loss: 101290.3203 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 58.3517 - val_loss: 83172.4062 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 51.2563\n",
            "Epoch 4/10\n",
            "204/204 [==============================] - 55s 269ms/step - loss: 69855.6406 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 45.7777 - val_loss: 57228.5938 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 40.0328\n",
            "Epoch 5/10\n",
            "204/204 [==============================] - 57s 279ms/step - loss: 48098.1797 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 36.0964 - val_loss: 39625.2891 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 31.7929\n",
            "Epoch 6/10\n",
            "204/204 [==============================] - 56s 273ms/step - loss: 33573.5547 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 29.0808 - val_loss: 28160.0840 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 26.0605\n",
            "Epoch 7/10\n",
            "204/204 [==============================] - 56s 274ms/step - loss: 24280.4746 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 24.3429 - val_loss: 21030.3418 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 22.4952\n",
            "Epoch 8/10\n",
            "204/204 [==============================] - 68s 332ms/step - loss: 18608.1836 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 21.4388 - val_loss: 16818.1855 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 20.4412\n",
            "Epoch 9/10\n",
            "204/204 [==============================] - 65s 321ms/step - loss: 15331.3564 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 19.7880 - val_loss: 14482.0156 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 19.4006\n",
            "Epoch 10/10\n",
            "204/204 [==============================] - 56s 273ms/step - loss: 13556.4111 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 18.9364 - val_loss: 13288.5156 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 19.0172\n"
          ]
        }
      ],
      "source": [
        "history_mmd, glocal_model_mmd = run_experiment(epochs=10, use_mse=True, metrics=[JointLoss().custom_sequence_MMD_loss,\n",
        "                                                                                  tf.keras.losses.mean_absolute_percentage_error])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_low_learning_rate, glocal_low_learning_rate = run_experiment(epochs=15, use_mse=True,learning_rate=0.0005,\n",
        "                                                                     metrics=[JointLoss().custom_sequence_MMD_loss, \n",
        "                                                                              tf.keras.losses.mean_absolute_percentage_error])"
      ],
      "metadata": {
        "id": "vkHRFMEpaXHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca615ec4-b99d-4f19-b255-eafd3dd12ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "204/204 [==============================] - 508s 688ms/step - loss: 232722.3750 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 97.5425 - val_loss: 222185.7188 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 95.1817\n",
            "Epoch 2/15\n",
            "204/204 [==============================] - 56s 275ms/step - loss: 214970.2344 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 93.0554 - val_loss: 205736.5312 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 90.8953\n",
            "Epoch 3/15\n",
            "204/204 [==============================] - 55s 271ms/step - loss: 199166.1562 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 88.8794 - val_loss: 190633.7812 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 86.7782\n",
            "Epoch 4/15\n",
            "204/204 [==============================] - 55s 272ms/step - loss: 184554.7031 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 84.8329 - val_loss: 176609.2656 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 82.7779\n",
            "Epoch 5/15\n",
            "204/204 [==============================] - 57s 278ms/step - loss: 170966.2969 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 80.9081 - val_loss: 163556.3281 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 78.8806\n",
            "Epoch 6/15\n",
            "204/204 [==============================] - 57s 279ms/step - loss: 158307.3438 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 77.0799 - val_loss: 151408.1562 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 75.0791\n",
            "Epoch 7/15\n",
            "204/204 [==============================] - 55s 270ms/step - loss: 146525.1875 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 73.3434 - val_loss: 140096.4062 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 71.3684\n",
            "Epoch 8/15\n",
            "204/204 [==============================] - 56s 276ms/step - loss: 135561.1406 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 69.7049 - val_loss: 129581.9531 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 67.7499\n",
            "Epoch 9/15\n",
            "204/204 [==============================] - 55s 271ms/step - loss: 125370.8203 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 66.1570 - val_loss: 119813.8203 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 64.2217\n",
            "Epoch 10/15\n",
            "204/204 [==============================] - 55s 270ms/step - loss: 115911.8047 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 62.7157 - val_loss: 110761.0625 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 60.7990\n",
            "Epoch 11/15\n",
            "204/204 [==============================] - 56s 276ms/step - loss: 107145.1094 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 59.3836 - val_loss: 102378.7656 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 57.4870\n",
            "Epoch 12/15\n",
            "204/204 [==============================] - 55s 272ms/step - loss: 99038.8906 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 56.1696 - val_loss: 94645.6562 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 54.3009\n",
            "Epoch 13/15\n",
            "204/204 [==============================] - 56s 272ms/step - loss: 91559.8984 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 53.0907 - val_loss: 87516.0078 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 51.2596\n",
            "Epoch 14/15\n",
            "204/204 [==============================] - 57s 279ms/step - loss: 84679.2969 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 50.1581 - val_loss: 80973.3047 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 48.3909\n",
            "Epoch 15/15\n",
            "204/204 [==============================] - 62s 305ms/step - loss: 78370.8203 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 47.3890 - val_loss: 74984.5156 - val_custom_sequence_MMD_loss: 0.0100 - val_mean_absolute_percentage_error: 45.7008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wKSm6QMuGuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4be73cf-1c86-4ec8-d4d1-36b52558e78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "255/255 [==============================] - 414s 249ms/step - loss: 197403.2812 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 88.3660\n",
            "Epoch 2/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 127435.2109 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 67.5425\n",
            "Epoch 3/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 80680.4375 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 50.2697\n",
            "Epoch 4/10\n",
            "255/255 [==============================] - 64s 250ms/step - loss: 50611.1797 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 37.2520\n",
            "Epoch 5/10\n",
            "255/255 [==============================] - 63s 249ms/step - loss: 32317.2383 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 28.5100\n",
            "Epoch 6/10\n",
            "255/255 [==============================] - 63s 247ms/step - loss: 21881.8242 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 23.2072\n",
            "Epoch 7/10\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 16363.6934 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 20.4176\n",
            "Epoch 8/10\n",
            "255/255 [==============================] - 63s 249ms/step - loss: 13689.2500 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 19.1406\n",
            "Epoch 9/10\n",
            "255/255 [==============================] - 64s 250ms/step - loss: 12545.0088 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 18.7035\n",
            "Epoch 10/10\n",
            "255/255 [==============================] - 68s 266ms/step - loss: 12116.4082 - custom_sequence_MMD_loss: 0.0100 - mean_absolute_percentage_error: 18.6410\n"
          ]
        }
      ],
      "source": [
        "#Running MMD with laplacian kernel\n",
        "history_laplacian, glocal_model_laplacian = run_experiment(epochs=10, use_mse=True, metrics=[JointLoss(mmd_kernel=\"laplacian\").custom_sequence_MMD_loss,\n",
        "                                                                                   tf.keras.losses.mean_absolute_percentage_error])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Running Experiment with preprocessing"
      ],
      "metadata": {
        "id": "hQg05uuoRtEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_preprocessed, glocal_model_preprocessed = run_experiment(preprocessed_sampled_dataX, preprocessed_sampled_dataY,\n",
        "                                                                 batch_size=20, dropout=0.0,\n",
        "                                                                 epochs=5, use_mse=True, metrics=[JointLoss().custom_sequence_MMD_loss,\n",
        "                                                                tf.keras.losses.mean_absolute_percentage_error], validation_split=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On6oHsxuRxFS",
        "outputId": "63b6e4bc-0e4d-40ed-97e3-730159a49bc3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1276/1276 [==============================] - 159s 68ms/step - loss: 98737.2578 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 55.2482\n",
            "Epoch 2/5\n",
            "1276/1276 [==============================] - 87s 68ms/step - loss: 16932.5859 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 21.2571\n",
            "Epoch 3/5\n",
            "1276/1276 [==============================] - 86s 68ms/step - loss: 13608.8154 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0370\n",
            "Epoch 4/5\n",
            "1276/1276 [==============================] - 89s 70ms/step - loss: 13599.4277 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0824\n",
            "Epoch 5/5\n",
            "1276/1276 [==============================] - 88s 69ms/step - loss: 13601.3604 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 20.0803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_interpolation_only, glocal_interpolation_only = run_experiment(preprocessed_sampled_dataX, preprocessed_sampled_dataY,\n",
        "                                                                 batch_size=20, dropout=0.0, exclude_locgen=True,\n",
        "                                                                 epochs=50, use_mse=True, metrics=[JointLoss().custom_sequence_MMD_loss,\n",
        "                                                                tf.keras.losses.mean_absolute_percentage_error], validation_split=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDY6p981x_s3",
        "outputId": "a0d804dd-fe9b-4534-9fa8-aa22b2ec7f4d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1276/1276 [==============================] - 141s 59ms/step - loss: 110383.3906 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 58.7814\n",
            "Epoch 2/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 35301.2734 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 27.5795\n",
            "Epoch 3/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 32216.2832 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4099\n",
            "Epoch 4/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 32205.5293 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4392\n",
            "Epoch 5/50\n",
            "1276/1276 [==============================] - 75s 59ms/step - loss: 32207.2930 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4488\n",
            "Epoch 6/50\n",
            "1276/1276 [==============================] - 73s 57ms/step - loss: 32206.7930 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4467\n",
            "Epoch 7/50\n",
            "1276/1276 [==============================] - 73s 57ms/step - loss: 32208.0723 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4365\n",
            "Epoch 8/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 32208.6699 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 26.4471\n",
            "Epoch 9/50\n",
            "1276/1276 [==============================] - 79s 61ms/step - loss: 31052.4609 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 25.7580\n",
            "Epoch 10/50\n",
            "1276/1276 [==============================] - 71s 55ms/step - loss: 17402.7324 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 19.2080\n",
            "Epoch 11/50\n",
            "1276/1276 [==============================] - 71s 56ms/step - loss: 11134.5576 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 16.0893\n",
            "Epoch 12/50\n",
            "1276/1276 [==============================] - 75s 59ms/step - loss: 9938.0078 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 14.7238\n",
            "Epoch 13/50\n",
            "1276/1276 [==============================] - 76s 60ms/step - loss: 9018.7461 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 13.2362\n",
            "Epoch 14/50\n",
            "1276/1276 [==============================] - 75s 59ms/step - loss: 6610.1406 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.7061\n",
            "Epoch 15/50\n",
            "1276/1276 [==============================] - 77s 60ms/step - loss: 5734.7432 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 11.0053\n",
            "Epoch 16/50\n",
            "1276/1276 [==============================] - 76s 60ms/step - loss: 5612.8594 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.8247\n",
            "Epoch 17/50\n",
            "1276/1276 [==============================] - 77s 60ms/step - loss: 5456.1230 - custom_sequence_MMD_loss: 0.0500 - mean_absolute_percentage_error: 10.5986\n",
            "Epoch 18/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 3430.4412 - custom_sequence_MMD_loss: 0.0059 - mean_absolute_percentage_error: 9.3402\n",
            "Epoch 19/50\n",
            "1276/1276 [==============================] - 77s 60ms/step - loss: 2807.2917 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.8020\n",
            "Epoch 20/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 2728.2947 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.6634\n",
            "Epoch 21/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 2608.4736 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.4890\n",
            "Epoch 22/50\n",
            "1276/1276 [==============================] - 75s 59ms/step - loss: 2509.5115 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.3174\n",
            "Epoch 23/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 2456.7878 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.2158\n",
            "Epoch 24/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 2400.3535 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 8.0894\n",
            "Epoch 25/50\n",
            "1276/1276 [==============================] - 74s 58ms/step - loss: 2341.5864 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.9903\n",
            "Epoch 26/50\n",
            "1276/1276 [==============================] - 73s 57ms/step - loss: 2347.4827 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.9664\n",
            "Epoch 27/50\n",
            "1276/1276 [==============================] - 75s 58ms/step - loss: 2280.2651 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.8612\n",
            "Epoch 28/50\n",
            "1276/1276 [==============================] - 75s 59ms/step - loss: 2234.0859 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.7568\n",
            "Epoch 29/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 2178.2563 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.6225\n",
            "Epoch 30/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 2167.1228 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.6043\n",
            "Epoch 31/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 2118.1819 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.5015\n",
            "Epoch 32/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 2099.0730 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.4640\n",
            "Epoch 33/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 2079.8726 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.4219\n",
            "Epoch 34/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 2054.1216 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.3609\n",
            "Epoch 35/50\n",
            "1276/1276 [==============================] - 80s 63ms/step - loss: 2029.0934 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.3138\n",
            "Epoch 36/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 2025.1219 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.3075\n",
            "Epoch 37/50\n",
            "1276/1276 [==============================] - 81s 63ms/step - loss: 2004.4445 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.2750\n",
            "Epoch 38/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 1980.0215 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.2169\n",
            "Epoch 39/50\n",
            "1276/1276 [==============================] - 80s 62ms/step - loss: 1973.3044 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.2060\n",
            "Epoch 40/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 1955.3142 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.1663\n",
            "Epoch 41/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 1924.5496 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.1028\n",
            "Epoch 42/50\n",
            "1276/1276 [==============================] - 80s 63ms/step - loss: 1909.6586 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.0678\n",
            "Epoch 43/50\n",
            "1276/1276 [==============================] - 80s 62ms/step - loss: 1906.1503 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.0604\n",
            "Epoch 44/50\n",
            "1276/1276 [==============================] - 81s 64ms/step - loss: 1873.4423 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 7.0053\n",
            "Epoch 45/50\n",
            "1276/1276 [==============================] - 80s 63ms/step - loss: 1865.8287 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 6.9831\n",
            "Epoch 46/50\n",
            "1276/1276 [==============================] - 81s 63ms/step - loss: 1845.3713 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 6.9450\n",
            "Epoch 47/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 1824.6331 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 6.8967\n",
            "Epoch 48/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 1813.9498 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 6.8666\n",
            "Epoch 49/50\n",
            "1276/1276 [==============================] - 79s 62ms/step - loss: 1812.5973 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 6.8693\n",
            "Epoch 50/50\n",
            "1276/1276 [==============================] - 78s 61ms/step - loss: 1782.2324 - custom_sequence_MMD_loss: 0.0000e+00 - mean_absolute_percentage_error: 6.8044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = glocal_model_preprocessed(sampled_dataX[:500])"
      ],
      "metadata": {
        "id": "fnqZvA_2S7xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_preprocessed.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdacxqutqdFA",
        "outputId": "146be108-f084-4657-83b1-78315f6d86c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [105492.7734375,\n",
              "  27768.814453125,\n",
              "  24599.69921875,\n",
              "  24588.44140625,\n",
              "  24589.66796875],\n",
              " 'custom_sequence_MMD_loss': [0.05001067370176315,\n",
              "  0.04999946057796478,\n",
              "  0.04999946057796478,\n",
              "  0.04999946057796478,\n",
              "  0.04999946057796478],\n",
              " 'mean_absolute_percentage_error': [56.47543716430664,\n",
              "  23.721494674682617,\n",
              "  22.558334350585938,\n",
              "  22.601720809936523,\n",
              "  22.604015350341797]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sampled_dataX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHHCNjKLp8wj",
        "outputId": "2e3306ff-7d19-40e7-cd6f-2932c87b9a5c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([25520, 10, 74])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = glocal_interpolation_only(sampled_dataX[:1000])"
      ],
      "metadata": {
        "id": "twUcXJOzrSSF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_sum = np.sum(np.reshape(predictions, (1000, 50*64)), axis=1)"
      ],
      "metadata": {
        "id": "Ce3ilE9P2CuD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0,1000), predictions_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "KIDvGYUVtTYx",
        "outputId": "ea1dddd2-0587-4901-8050-5c82ac7456e5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb8dd9afd10>]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0,40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DePBtlZo2eH4",
        "outputId": "e972c9af-e4e7-4366-a0f6-cfc939a091f7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([499.64008, 393.31113, 499.29443, 391.07764, 497.85376, 467.2621 ,\n",
              "       497.0074 , 546.8737 , 497.5136 , 555.29626, 498.095  , 556.13086,\n",
              "       497.57492,   0.     , 496.9591 , 468.6987 , 495.56912,   0.     ,\n",
              "       498.03033, 516.8565 , 498.37735,   0.     ,   0.     , 394.4756 ,\n",
              "       499.26846,   0.     , 499.25897, 292.53564, 501.68973, 278.7328 ,\n",
              "       501.2714 , 257.40393, 499.00772, 291.9477 , 497.54233, 303.69714,\n",
              "       494.48853, 348.00888, 496.6417 , 364.3534 , 496.60992, 359.97226,\n",
              "       498.6779 , 357.46896, 497.94403,   0.     , 486.7406 , 367.7068 ,\n",
              "       499.89502, 291.69922, 499.36005, 304.19553, 499.27658, 350.0115 ,\n",
              "       498.9949 , 354.28555, 501.09012, 355.42294, 499.81827, 345.67166,\n",
              "       500.00015, 355.6395 , 487.54526, 348.5882 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_dataY[0,40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3axSdTYG2svm",
        "outputId": "5c702d7c-0560-43f0-8901-d665f02f689e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([485.3502, 439.2325, 503.4748, 435.6133, 493.6432, 530.1279,\n",
              "       508.2068, 624.7448, 479.209 , 626.8907, 466.192 , 622.8315,\n",
              "       466.4923, 443.0063, 462.1733, 540.3649, 464.5618, 640.1575,\n",
              "       445.6652, 635.116 , 437.1776, 630.0218, 485.3471, 439.2106,\n",
              "       499.5153, 390.0015, 503.806 , 332.4882, 491.736 , 311.5186,\n",
              "       497.3286, 288.2282, 503.806 , 332.4882, 482.3312, 348.664 ,\n",
              "       443.6775, 399.6154, 397.1931, 413.2619, 397.1931, 413.2619,\n",
              "       392.1533, 395.7729, 377.223 , 422.1048, 377.223 , 422.1048,\n",
              "       503.806 , 332.4882, 519.8842, 348.6104, 509.5627, 393.0717,\n",
              "       476.2727, 411.3513, 476.2727, 411.3513, 464.8629, 394.3017,\n",
              "       461.6813, 423.342 , 461.6813, 423.342 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0,20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtvRxsBQ2mcX",
        "outputId": "0fa47d39-b36a-4de0-ba4d-268a18676c20"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([443.58624, 369.5602 , 442.23962, 367.2112 , 439.67337, 439.1234 ,\n",
              "       439.26096, 513.185  , 439.73978, 519.701  , 440.11786, 521.55237,\n",
              "       440.64777,   0.     , 438.39886, 440.63422, 438.5919 ,   0.     ,\n",
              "       440.1264 , 473.18774, 441.13992,   0.     ,   0.     , 370.99512,\n",
              "       442.1821 ,   0.     , 440.93433, 275.13818, 444.66776, 261.7531 ,\n",
              "       444.07687, 241.81474, 441.33365, 274.4613 , 440.67145, 285.65732,\n",
              "       437.76538, 326.78577, 439.63312, 341.17798, 439.83072, 333.09637,\n",
              "       442.03882, 336.001  , 441.0297 ,   0.     , 436.82785, 344.29208,\n",
              "       442.54062, 274.3468 , 441.92145, 286.24762, 440.9555 , 329.27298,\n",
              "       440.2855 , 332.70413, 442.79596, 333.49255, 440.80023, 324.20325,\n",
              "       441.44162, 333.43457, 436.45276, 322.73215], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlbzBryCtvUn",
        "outputId": "4c95fd16-4af5-42eb-acf7-5c83ff21c563"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1160054.2 , 1139419.5 , 1139419.5 , 1139156.6 , 1139419.5 ,\n",
              "       1139419.5 , 1169055.8 , 1190666.  , 1175398.5 , 1173626.1 ,\n",
              "       1173626.1 , 1190746.9 , 1191585.5 , 1174099.8 , 1178801.2 ,\n",
              "       1173499.9 , 1173986.  , 1139419.5 , 1173886.  , 1163687.2 ,\n",
              "       1155465.2 , 1162337.9 , 1175908.  , 1149197.6 , 1173986.2 ,\n",
              "       1174099.8 , 1157047.2 , 1157047.2 , 1157047.2 , 1157047.2 ,\n",
              "       1157047.2 , 1157047.2 , 1157047.2 , 1165152.  , 1157047.2 ,\n",
              "       1171234.  , 1204183.5 , 1200475.1 , 1174860.6 , 1157047.2 ,\n",
              "       1157059.5 , 1191921.9 , 1191548.  , 1191921.9 , 1154890.8 ,\n",
              "       1171015.9 , 1156491.4 , 1156489.6 , 1156603.8 , 1157047.2 ,\n",
              "       1177176.5 , 1172458.4 , 1227210.5 , 1194433.4 , 1168862.  ,\n",
              "       1166813.8 , 1194276.  , 1194272.2 , 1168856.5 , 1180656.4 ,\n",
              "       1166873.  , 1182095.8 , 1180682.2 , 1180681.9 , 1208876.8 ,\n",
              "       1223079.4 , 1221949.2 , 1169363.5 , 1165725.2 , 1166026.4 ,\n",
              "       1166936.8 , 1180913.4 , 1180741.6 , 1180963.8 , 1178053.1 ,\n",
              "       1182199.8 , 1226943.  , 1227210.8 , 1227210.5 , 1223565.  ,\n",
              "       1200488.9 , 1180570.8 , 1184322.6 , 1167174.8 , 1180656.2 ,\n",
              "       1180656.2 , 1180656.2 , 1180681.9 , 1180658.1 , 1166950.  ,\n",
              "       1215177.  , 1205493.2 , 1187219.2 , 1180684.8 , 1180681.8 ,\n",
              "       1200090.5 , 1200313.1 , 1165312.9 , 1180559.6 , 1165669.  ,\n",
              "       1227210.5 , 1160054.2 , 1153998.6 , 1173986.  , 1173986.  ,\n",
              "       1173986.  , 1164505.  , 1190398.2 , 1190398.2 , 1190398.2 ,\n",
              "       1174087.6 , 1173626.1 , 1163687.2 , 1159395.2 , 1170008.5 ,\n",
              "       1171571.8 , 1191745.5 , 1174102.5 , 1169997.2 , 1186879.  ,\n",
              "       1173986.2 , 1174099.8 , 1174099.8 , 1161386.2 , 1175394.8 ,\n",
              "       1161286.2 , 1165686.2 , 1161295.  , 1175394.8 , 1175394.8 ,\n",
              "       1160170.8 , 1172670.4 , 1165583.2 , 1161279.6 , 1161279.6 ,\n",
              "       1172779.8 , 1168386.8 , 1160170.8 , 1160170.8 , 1160170.8 ,\n",
              "       1160170.8 , 1160054.2 , 1165434.4 , 1163687.2 , 1158679.8 ,\n",
              "       1164354.5 , 1160265.5 , 1165921.5 , 1160170.8 , 1160170.8 ,\n",
              "       1174898.6 , 1174099.8 , 1174099.8 , 1169157.1 , 1174099.8 ,\n",
              "       1160170.8 , 1174082.8 , 1174099.8 , 1176660.5 , 1167156.  ,\n",
              "       1173995.2 , 1160171.8 , 1172583.2 , 1174099.8 , 1174020.8 ,\n",
              "       1160170.8 , 1172779.2 , 1172779.8 , 1172779.8 , 1172780.  ,\n",
              "       1172779.8 , 1160170.8 , 1172779.8 , 1160170.8 , 1160170.8 ,\n",
              "       1172779.8 , 1171724.8 , 1174599.4 , 1160170.8 , 1162864.5 ,\n",
              "       1161197.8 , 1174099.  , 1161401.6 , 1139419.6 , 1139419.8 ,\n",
              "       1169806.5 , 1142997.9 , 1159550.4 , 1171004.2 , 1171004.2 ,\n",
              "       1159047.5 , 1171004.2 , 1171004.2 , 1195546.  , 1157429.5 ,\n",
              "       1190399.2 , 1205861.  , 1201097.2 , 1196531.5 , 1165444.5 ,\n",
              "       1171004.5 , 1180020.5 , 1171004.2 , 1164324.8 , 1158751.  ,\n",
              "       1169028.2 , 1170008.5 , 1167745.  , 1171570.1 , 1170008.5 ,\n",
              "       1171004.2 , 1171004.2 , 1171004.2 , 1191745.5 , 1178115.1 ,\n",
              "       1178115.1 , 1178115.2 , 1191745.5 , 1191745.5 , 1178115.1 ,\n",
              "       1177275.9 , 1178118.5 , 1178115.1 , 1178115.1 , 1171513.2 ,\n",
              "       1176727.9 , 1167515.5 , 1166346.9 , 1183403.  , 1189296.9 ,\n",
              "       1177725.8 , 1179903.9 , 1170622.2 , 1157252.4 , 1157086.1 ,\n",
              "       1166346.8 , 1177297.8 , 1166415.8 , 1178115.  , 1177289.8 ,\n",
              "       1177275.9 , 1177275.9 , 1177406.2 , 1191745.5 , 1177451.1 ,\n",
              "       1177275.9 , 1177475.5 , 1177275.9 , 1191744.8 , 1177276.  ,\n",
              "       1177275.9 , 1191492.8 , 1177344.  , 1177277.8 , 1166173.4 ,\n",
              "       1177359.5 , 1177276.  , 1177275.9 , 1177276.2 , 1177275.9 ,\n",
              "       1177275.9 , 1180221.6 , 1169862.9 , 1177605.5 , 1177275.9 ,\n",
              "       1189296.9 , 1173970.6 , 1189296.9 , 1177275.9 , 1177275.9 ,\n",
              "       1178152.2 , 1177276.  , 1166347.1 , 1177551.1 , 1185625.2 ,\n",
              "       1177275.9 , 1157593.8 , 1172149.6 , 1171004.2 , 1171004.2 ,\n",
              "       1171004.2 , 1159091.2 , 1185953.1 , 1185953.1 , 1212411.4 ,\n",
              "       1203061.  , 1197337.  , 1171504.  , 1098735.5 , 1073549.2 ,\n",
              "       1060698.  , 1182922.5 , 1170008.5 , 1184414.8 , 1181292.5 ,\n",
              "       1172568.4 , 1200775.2 , 1171237.1 , 1182003.5 , 1164859.4 ,\n",
              "       1166590.8 , 1178115.  , 1157048.9 , 1178114.8 , 1157047.2 ,\n",
              "       1182123.9 , 1203795.4 , 1198148.4 , 1203293.  , 1203293.  ,\n",
              "       1156489.6 , 1177442.4 , 1177434.5 , 1159581.  , 1176297.8 ,\n",
              "       1178187.5 , 1177633.9 , 1177287.  , 1194755.  , 1190398.2 ,\n",
              "       1178001.9 , 1190213.  , 1173628.5 , 1163687.2 , 1163687.2 ,\n",
              "       1173099.6 , 1163687.2 , 1163687.2 , 1185076.5 , 1181683.5 ,\n",
              "       1181683.5 , 1190398.2 , 1163687.2 , 1163683.  , 1174540.2 ,\n",
              "       1163687.8 , 1181819.5 , 1168073.5 , 1190284.5 , 1163693.4 ,\n",
              "       1130942.  , 1098573.8 , 1163687.2 , 1163689.8 , 1163687.1 ,\n",
              "       1163676.6 , 1174175.2 , 1098585.6 , 1098540.8 , 1130942.  ,\n",
              "       1130942.  , 1098573.8 , 1098573.8 , 1098573.8 , 1098573.8 ,\n",
              "       1130942.  , 1130942.  , 1163687.2 , 1162677.5 , 1130942.  ,\n",
              "       1130942.  , 1163687.2 , 1130942.  , 1163964.8 , 1163687.2 ,\n",
              "       1163687.2 , 1165055.8 , 1097989.4 , 1165431.2 , 1163687.2 ,\n",
              "       1163687.2 , 1163869.6 , 1129070.6 , 1129070.6 , 1129094.  ,\n",
              "       1163703.4 , 1131001.8 , 1111912.4 , 1098573.8 , 1098613.9 ,\n",
              "       1103820.2 , 1098782.4 , 1097846.1 , 1097991.  , 1085763.4 ,\n",
              "       1095205.6 , 1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 ,\n",
              "       1187374.1 , 1187374.1 , 1214263.1 , 1195436.  , 1187374.1 ,\n",
              "       1187372.8 , 1187319.8 , 1199781.8 , 1213295.  , 1215290.  ,\n",
              "       1200374.8 , 1193846.1 , 1208547.2 , 1215290.  , 1187374.1 ,\n",
              "       1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 ,\n",
              "       1211883.9 , 1215290.  , 1187374.1 , 1187374.1 , 1187374.1 ,\n",
              "       1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 ,\n",
              "       1187374.1 , 1187374.1 , 1187374.1 , 1187406.9 , 1187374.1 ,\n",
              "       1187374.1 , 1187374.1 , 1213996.5 , 1187372.9 , 1187335.  ,\n",
              "       1187374.1 , 1187285.8 , 1187275.5 , 1202614.8 , 1199945.2 ,\n",
              "       1215177.5 , 1215181.4 , 1187373.9 , 1215310.5 , 1187374.1 ,\n",
              "       1215290.  , 1202375.8 , 1205364.5 , 1196968.5 , 1215290.  ,\n",
              "       1187374.1 , 1187374.1 , 1200938.8 , 1187374.1 , 1172655.  ,\n",
              "       1167045.2 , 1175730.8 , 1184620.2 , 1186930.5 , 1191745.5 ,\n",
              "       1186879.  , 1174176.4 , 1174099.8 , 1173103.5 , 1178713.  ,\n",
              "       1191745.5 , 1174099.8 , 1179217.4 , 1174164.9 , 1172654.1 ,\n",
              "       1175407.4 , 1178016.4 , 1177275.9 , 1177276.5 , 1177275.9 ,\n",
              "       1191744.5 , 1191745.5 , 1177684.5 , 1191743.8 , 1191798.  ,\n",
              "       1177598.5 , 1177275.9 , 1177275.9 , 1178136.1 , 1178115.  ,\n",
              "       1178115.1 , 1172076.2 , 1166346.8 , 1177275.9 , 1177450.2 ,\n",
              "       1177428.5 , 1177275.9 , 1177275.9 , 1177508.6 , 1177275.9 ,\n",
              "       1181821.2 , 1177450.  , 1189686.9 , 1191745.5 , 1196038.9 ,\n",
              "       1172654.1 , 1177432.8 , 1191745.5 , 1191745.5 , 1191745.5 ,\n",
              "       1191742.1 , 1191745.5 , 1191745.5 , 1177286.4 , 1177276.  ,\n",
              "       1177275.9 , 1177275.9 , 1177276.8 , 1177275.9 , 1178117.5 ,\n",
              "       1178115.  , 1178752.2 , 1181730.  , 1227210.5 , 1215257.4 ,\n",
              "       1210983.4 , 1187374.1 , 1194786.2 , 1180550.6 , 1180552.8 ,\n",
              "       1193451.  , 1194215.9 , 1195985.1 , 1215177.2 , 1187374.1 ,\n",
              "       1187374.1 , 1207511.  , 1193303.5 , 1227211.  , 1187374.1 ,\n",
              "       1187374.1 , 1215290.  , 1187374.1 , 1193007.4 , 1185686.2 ,\n",
              "       1181680.5 , 1187373.  , 1182115.  , 1187373.2 , 1215290.  ,\n",
              "       1201143.9 , 1215290.  , 1200920.1 , 1200920.1 , 1200920.9 ,\n",
              "       1200920.5 , 1201303.5 , 1200931.9 , 1187374.1 , 1187430.5 ,\n",
              "       1205430.1 , 1201793.8 , 1215290.  , 1215290.  , 1194682.5 ,\n",
              "       1187374.1 , 1200897.8 , 1187374.1 , 1214594.4 , 1222271.8 ,\n",
              "       1187374.5 , 1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 ,\n",
              "       1187374.1 , 1187373.6 , 1187302.8 , 1187309.5 , 1201872.6 ,\n",
              "       1201978.2 , 1201157.5 , 1215230.2 , 1187374.1 , 1214512.2 ,\n",
              "       1187374.1 , 1187601.2 , 1120318.1 , 1098460.1 , 1098540.8 ,\n",
              "       1089791.8 , 1129070.6 , 1105616.2 , 1098470.2 , 1112125.4 ,\n",
              "       1097993.5 , 1076340.2 , 1083243.  , 1098086.8 , 1096928.9 ,\n",
              "       1098458.8 , 1098486.4 , 1130942.  , 1099947.6 , 1104265.2 ,\n",
              "       1098209.2 ,  981341.6 ,  982382.25,  982382.25, 1098573.8 ,\n",
              "       1098616.2 , 1098458.8 , 1104346.5 , 1098573.8 , 1129070.6 ,\n",
              "       1099238.4 , 1143789.2 , 1163687.2 , 1163687.2 , 1129070.6 ,\n",
              "       1163687.2 , 1129070.5 , 1163870.2 , 1140784.5 , 1130942.1 ,\n",
              "       1163687.2 , 1129070.9 , 1098573.8 , 1097848.8 , 1135685.5 ,\n",
              "       1130942.1 , 1098440.  , 1130942.  , 1130942.  , 1104422.  ,\n",
              "       1130942.  , 1112715.2 , 1115106.1 , 1098121.  , 1147609.4 ,\n",
              "       1163687.2 , 1163687.2 , 1162168.  , 1144467.8 , 1152756.1 ,\n",
              "       1141978.8 , 1098017.5 , 1098536.4 , 1104003.8 , 1098001.2 ,\n",
              "       1166346.8 , 1178589.1 , 1177276.  , 1166346.8 , 1178419.  ,\n",
              "       1178115.1 , 1178101.  , 1178053.1 , 1178114.5 , 1178114.5 ,\n",
              "       1166346.8 , 1180598.9 , 1177278.2 , 1172654.1 , 1183238.1 ,\n",
              "       1172654.1 , 1177442.4 , 1177442.4 , 1172779.8 , 1177442.4 ,\n",
              "       1166362.2 , 1178616.4 , 1177275.9 , 1166346.8 , 1177719.6 ,\n",
              "       1176123.8 , 1170710.4 , 1173306.  , 1172779.8 , 1161330.6 ,\n",
              "       1172779.8 , 1172779.8 , 1161280.1 , 1177275.9 , 1161279.6 ,\n",
              "       1177433.  , 1177442.4 , 1177368.  , 1177339.6 , 1173731.9 ,\n",
              "       1161279.6 , 1177442.5 , 1177442.4 , 1177283.8 , 1189897.9 ,\n",
              "       1171375.  , 1172654.1 , 1173852.8 , 1162214.8 , 1191745.5 ,\n",
              "       1191745.5 , 1175394.8 , 1175469.8 , 1172992.2 , 1161279.6 ,\n",
              "       1172780.2 , 1164712.6 , 1160182.2 , 1172779.8 , 1172779.8 ,\n",
              "       1161283.1 , 1161535.2 , 1161776.8 , 1161500.8 , 1177725.8 ,\n",
              "       1177725.8 , 1189296.9 , 1177725.8 , 1177725.8 , 1166356.5 ,\n",
              "       1177725.8 , 1189296.9 , 1189296.9 , 1189296.9 , 1189296.9 ,\n",
              "       1183382.8 , 1185503.8 , 1177275.9 , 1189296.9 , 1189296.9 ,\n",
              "       1186208.9 , 1177275.9 , 1189296.9 , 1171907.  , 1166192.1 ,\n",
              "       1189642.5 , 1179905.  , 1166310.5 , 1166318.8 , 1177178.2 ,\n",
              "       1192277.4 , 1209528.1 , 1215290.  , 1212942.4 , 1178056.6 ,\n",
              "       1172777.8 , 1160170.8 , 1207808.2 , 1200848.2 , 1227373.8 ,\n",
              "       1227210.5 , 1227210.5 , 1227210.5 , 1165858.2 , 1177725.8 ,\n",
              "       1177725.8 , 1177725.8 , 1177725.8 , 1177725.8 , 1177725.8 ,\n",
              "       1177725.8 , 1190092.1 , 1189296.9 , 1189302.2 , 1189296.9 ,\n",
              "       1177725.8 , 1177725.8 , 1190034.5 , 1178115.  , 1177725.8 ,\n",
              "       1177725.8 , 1178996.1 , 1178087.5 , 1177725.8 , 1177725.8 ,\n",
              "       1176371.5 , 1165725.8 , 1166251.8 , 1166163.4 , 1165834.  ,\n",
              "       1165861.  , 1178111.9 , 1177446.4 , 1178115.1 , 1157047.2 ,\n",
              "       1227210.4 , 1221862.2 , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1191508.1 , 1227216.2 , 1208797.1 , 1188846.5 , 1156007.8 ,\n",
              "       1174111.  , 1177275.9 , 1192373.5 , 1227210.5 , 1227210.5 ,\n",
              "       1226031.2 , 1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1227160.9 , 1227210.5 , 1227210.5 , 1227210.5 , 1227210.2 ,\n",
              "       1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1213459.8 , 1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 , 1207560.  ,\n",
              "       1176972.2 , 1120109.8 , 1189172.  , 1211339.8 , 1215182.5 ,\n",
              "       1215250.5 , 1191954.8 , 1190396.8 , 1125584.9 , 1166346.8 ,\n",
              "       1166346.8 , 1151344.  , 1226590.2 , 1227210.5 , 1227212.  ,\n",
              "       1227210.4 , 1225803.5 , 1213975.2 , 1185442.2 , 1187374.1 ,\n",
              "       1187374.1 , 1187374.1 , 1200807.4 , 1227210.4 , 1187374.2 ,\n",
              "       1187374.1 , 1187374.1 , 1187374.1 , 1187374.1 , 1187258.8 ,\n",
              "       1186346.2 , 1187163.  , 1187250.  , 1138305.2 , 1125573.8 ,\n",
              "       1103548.  , 1137968.5 , 1137909.  , 1137567.  , 1138047.2 ,\n",
              "       1137843.  , 1137854.2 , 1138046.5 , 1137690.  , 1138090.  ,\n",
              "       1137567.  , 1137564.5 , 1137723.5 , 1137567.  , 1137568.  ,\n",
              "       1137567.  , 1138032.2 , 1137567.2 , 1137567.  , 1137567.  ,\n",
              "       1137961.  , 1141196.  , 1138031.6 , 1115894.2 , 1107145.5 ,\n",
              "        985008.5 , 1004089.7 , 1185974.6 , 1191921.9 , 1178056.8 ,\n",
              "       1172732.8 , 1056857.8 ,  987741.4 ,  996230.94, 1053070.2 ,\n",
              "       1053029.  , 1117147.6 , 1172654.1 , 1172654.1 , 1173718.2 ,\n",
              "       1174944.4 , 1160073.2 , 1191510.2 , 1190398.2 , 1191745.5 ,\n",
              "       1177449.4 , 1175394.8 , 1161279.6 , 1172654.1 , 1161887.5 ,\n",
              "       1190398.2 , 1174236.4 , 1174886.2 , 1173626.1 , 1189796.8 ,\n",
              "       1173626.1 , 1190398.2 , 1173626.1 , 1227210.5 , 1227210.5 ,\n",
              "       1225902.  , 1226013.5 , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1227210.5 , 1227208.  , 1227210.5 , 1227210.5 , 1227208.  ,\n",
              "       1227210.5 , 1226535.  , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1227210.5 , 1227210.5 , 1227210.5 , 1226012.1 , 1226012.1 ,\n",
              "       1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 , 1227210.5 ,\n",
              "       1227210.5 , 1226548.8 , 1187187.8 , 1215178.  , 1207730.8 ,\n",
              "       1177277.  , 1165318.5 , 1117033.2 , 1156443.9 , 1175165.2 ,\n",
              "       1194091.6 , 1157047.2 , 1182105.1 , 1192271.5 , 1207867.9 ,\n",
              "       1187261.9 , 1180547.2 , 1171004.2 , 1157047.2 , 1157048.8 ,\n",
              "       1176780.  , 1157047.2 , 1157047.2 , 1157047.2 , 1157047.5 ,\n",
              "       1166336.1 , 1170357.8 , 1166356.6 , 1178321.  , 1166347.  ,\n",
              "       1179158.9 , 1171004.2 , 1157047.2 , 1157047.2 , 1192070.2 ,\n",
              "       1191585.5 , 1157047.2 , 1172804.1 , 1192243.  , 1164493.  ,\n",
              "       1169278.6 , 1157047.2 , 1157047.2 , 1157047.2 , 1194853.1 ,\n",
              "       1195822.2 , 1180857.  , 1192999.2 , 1019444.3 , 1083470.5 ,\n",
              "       1165145.2 , 1222576.1 , 1180656.2 , 1180747.8 , 1166913.8 ,\n",
              "       1170200.2 , 1189603.  , 1103355.2 , 1103418.1 , 1112081.5 ,\n",
              "       1138032.2 , 1103559.5 , 1103418.5 , 1103418.1 , 1103418.1 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[1,20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fgfyOwgsOn8",
        "outputId": "17f11efc-b7fb-4880-b960-39eb75285ad3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([530.94775, 425.6861 , 530.23944, 424.00946, 529.30835, 492.00867,\n",
              "       528.04156, 575.09564, 528.47095, 585.08746, 528.69666, 584.4934 ,\n",
              "       531.6108 , 427.43073, 531.9095 , 494.02744, 529.5448 , 577.68335,\n",
              "       530.5533 , 585.51886, 531.1571 , 583.38934, 530.949  , 425.67795,\n",
              "       531.71704, 374.9985 , 532.9671 ,   0.     , 533.7336 , 307.53113,\n",
              "       533.91907, 285.0529 , 532.96826, 321.42844, 533.49445, 332.89484,\n",
              "       533.4907 ,   0.     , 534.10645, 393.93924, 534.1124 , 393.94028,\n",
              "       534.48303, 385.5388 , 534.5305 , 396.38873, 534.5232 , 396.38828,\n",
              "       532.96906, 321.42596, 531.7403 , 333.57785, 529.7442 , 377.8631 ,\n",
              "       529.9651 , 383.5723 , 529.9628 , 383.57132, 530.5732 , 375.54   ,\n",
              "       530.1568 , 383.54843, 530.1601 , 383.54987], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o1x1hlGgsUNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = glocal_model_preprocessed.evaluate(sampled_dataX, sampled_dataY)"
      ],
      "metadata": {
        "id": "mXGZJWfBrFda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "fb3e2267-b0f6-4ae0-b6b4-13ffce7a478f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-66bfb4ea3b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglocal_model_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_dataX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_dataY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"glocal_net\" (type GlocalNet).\n    \n    in user code:\n    \n        File \"<ipython-input-17-2b985502f069>\", line 40, in call  *\n            interpolated_frames = self.interpolation_layer(glogen_output)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"interpolation_layer\" (type InterpolationLayer).\n        \n        in user code:\n        \n            File \"<ipython-input-16-d3fd1ef9a66e>\", line 41, in call  *\n                return self.interpolateFrames(inputs)\n            File \"<ipython-input-16-d3fd1ef9a66e>\", line 23, in interpolateFrames  *\n                for batch in range(batch_size) :\n        \n            TypeError: 'NoneType' object cannot be interpreted as an integer\n        \n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(None, 10, 64), dtype=float32)\n    \n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 10, 74), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yue79_F0pVOu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "snGEPtNOKLvg",
        "KTHffB1KrfBy",
        "H-ekHZVlrq1o"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}